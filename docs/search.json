[{"path":"/articles/simplifyEnrichment_intro.html","id":"simplify-go-enrichment-results","dir":"Articles","previous_headings":"","what":"Simplify GO enrichment results","title":"Simplify Functional Enrichment Results","text":"major use case simplifyEnrichment simplying GO enrichment results clustering corresponding semantic similarity matrix significant GO terms. demonstrate usage, first generate list random GO IDs Biological Process (BP) ontology category: simplifyEnrichment starts GO similarity matrix. Users can use similarity matrices use GO_similarity() function calculate semantic similarity matrix. GO_similarity() function simply wrapper GOSemSim::termSim(). function accepts vector GO IDs. Note GO terms belong one ontology (.e., BP, CC MF). default, GO_similarity() uses Rel method GOSemSim::termSim(). methods calculate GO similarities can set measure argument, e.g.: similarity matrix mat, users can directly apply simplifyGO() function perform clustering well visualizing results.  right side heatmap word cloud annotations summarize functions keywords every GO cluster. Additionally, enrichment done keywords compared GO background vocabulary significance corresponds font size keywords. Note word cloud cluster merged small clusters (size < 5). returned variable df data frame GO IDs cluster labels: size GO clusters can retrieved : split data frame cluster labels: plot argument can set FALSE simplifyGO(), plot generated data frame returned. aim cluster GO terms, binary_cut() cluster_terms() functions can directly applied: binary_cut() cluster_terms() basically generate clusterings, labels clusters might differ.","code":"library(simplifyEnrichment) set.seed(888) go_id = random_GO(500) mat = GO_similarity(go_id) GO_similarity(go_id, measure = \"Wang\") df = simplifyGO(mat) head(df) ##           id cluster ## 1 GO:0086066       1 ## 2 GO:0090461       2 ## 3 GO:0032912       3 ## 4 GO:0090220       4 ## 5 GO:0032495       5 ## 6 GO:0070585       4 sort(table(df$cluster)) ##  ##  15  16  17  18  19   8   9  14  10  12  13  11   6   2   7   4   5   1   3  ##   1   1   1   1   1   2   2   2   5   5   5   8  10  14  31  71  83 110 147 split(df, df$cluster) binary_cut(mat) ##   [1]  1  2  3  4  5  4  4  4  1  3  3  5  1  5  1  4  1  4  5  4  5  1  4  3  6 ##  [26]  3  7  4  3  1  1  3  8  7  3  3  5  1  4  4  5  2  4  9  5  1  1  7  3  7 ##  [51]  5  3 10  7  1  7  3 10  3  3  7  1  5  5  3  1  1  1  1  3  1  4 11  3  1 ##  [76]  3  4  7  3  3  1  5  4  6  3  3  1  5  4  5  7  3  3  4  5  3  1  1  4  6 ## [101]  4  3  4  4  1  4  3  5  3  7  3  1  3  3  3  1  1  1  9  4  4  8  3  1  1 ## [126]  1  1  5  4  1  4  1  3  5  5  5  1  5  3  5  5  5  1  3  5  5 12  1  2  4 ## [151]  8  3  7  1  3  5  8  1  4  5  1  5  1  1  5  3  3  4  1  1  3  3  3  1  4 ## [176]  4  1  3  4  3  3 13  5  4  4  3  1  3  5  3  5  3  3  3  1  1  1  5  4  3 ## [201]  2  5  4  4  2  3  1  1  3  3  1  2  3  3  3  4  5  3  4  3  4  6  6  4  7 ## [226]  4  5  5  1  1  3  1 10  8  7  7  5  5  3  3  7  3  1  4  1  1  5  6  3  5 ## [251]  5  1 14  1  3 11  4  1  5 12  3  1  7  3  1  5  1  3  5  5  3  6  1  5  3 ## [276] 11  1  2  3  4  5 12  1  1 10  3  5  3  3  3  7  4  5  3  3  4  1  1  4  7 ## [301]  3  2  4  5  3  3  5  3  1  3  2  5  2  3  3  1  1  5  5  4 11  1  1  5  3 ## [326]  3  1  4  5  1  1  1  1  7  3  2  3  2  5  3  5  1 12  3  3  4  3  1  4  6 ## [351]  4  7  1  3  1  4  7  3  5  3  1  2 11  4  3  3  1  1  1  5  7  7  1  1  3 ## [376]  5  3  7  3 10  1  3  1  7  3  1  3 11  3 15  4  6  3  1  3  7  6  1  5  4 ## [401]  5  3  1  3  3  5  3  3  7  4  5  1  7  5  7  3  1  8  3  3 10  1  1  4  3 ## [426]  1  3 12  1  3  3  1  1  5  3  3  1  1  1  1 16  5  1  3  7  3  1  5  1  5 ## [451]  7  3  4  5  4  4  1  1  3  5  7 11  4  4  5  3  4  4  1  1  3  5  8  5  3 ## [476]  3  3  3  5 17  3  3  3  4  1 11  5  1  3  3  1  5  3  1  3 18  7  5  3  1 cluster_terms(mat, method = \"binary_cut\")"},{"path":"/articles/simplifyEnrichment_intro.html","id":"comparing-clustering-methods","dir":"Articles","previous_headings":"","what":"Comparing clustering methods","title":"Simplify Functional Enrichment Results","text":"simplifyEnrichment package, also functions compare clustering results different methods. still use previously generated variable mat similarity matrix 500 random GO terms. Simply running compare_clustering_methods() function performs supported methods (all_clustering_methods()) excluding mclust, mclust usually takes long time run. function generates figure three panels: heatmap similarity matrix different clusterings row annotations. heatmap pair-wise concordance clustering every two methods. Barplots difference scores method, number clusters (total clusters clusters size >= 5) mean similarity terms clusters (block mean). barplots, three metrics defined follows: Different score: difference similarity values terms belong clusters different clusters. similarity matrix \\(M\\), term \\(\\) term \\(j\\) \\(\\ne j\\), similarity value \\(x_{,j}\\) saved vector \\(\\mathbf{x_1}\\) term \\(\\) \\(j\\) cluster. \\(x_{,j}\\) saved vector \\(\\mathbf{x_2}\\) term \\(\\) \\(j\\) cluster. difference score measures distribution difference \\(\\mathbf{x_1}\\) \\(\\mathbf{x_2}\\), calculated Kolmogorov-Smirnov statistic two distributions. Number clusters: clustering, two numbers: number total clusters number clusters size >= 5 (big clusters). Block mean: Mean similarity values diagonal blocks similarity heatmap. Using convention difference score, block mean mean value \\(\\mathbf{x_1}\\).  plot_type argument set heatmap. heatmaps similarity matrix different clusterings methods. last panel table number clusters.  Please note, clustering methods might randomness, means, different runs compare_clustering_methods() may generate different clusterings (slightly different). Thus, users want compare plots compare_clustering_methods(mat) compare_clustering_methods(mat, plot_type = \"heatmap\"), set random seed executing function. compare_clustering_methods() simply wrapper cmp_make_clusters() cmp_make_plot() functions former function performs clustering different methods latter visualizes results. compare different plots, users can also use following code without specifying random seed.","code":"compare_clustering_methods(mat) compare_clustering_methods(mat, plot_type = \"heatmap\") set.seed(123) compare_clustering_methods(mat) set.seed(123) compare_clustering_methods(mat, plot_type = \"heatmap\") clt = cmp_make_clusters(mat) # just a list of cluster labels cmp_make_plot(mat, clt) cmp_make_plot(mat, clt, plot_type = \"heatmap\")"},{"path":"/articles/simplifyEnrichment_intro.html","id":"register-new-clustering-methods","dir":"Articles","previous_headings":"Comparing clustering methods","what":"Register new clustering methods","title":"Simplify Functional Enrichment Results","text":"New clustering methods can added register_clustering_methods(), removed remove_clustering_methods() reset default methods reset_clustering_methods(). supported methods can retrieved all_clustering_methods(). compare_clustering_methods() runs clustering methods all_clustering_methods(). new clustering methods user-defined functions sent register_clustering_methods() named arguments, e.g.: functions accept least one argument input matrix (mat example). second optional argument always ... parameters clustering function can passed control argument cluster_terms() simplifyGO(). users forget add ..., added internally. Please note, user-defined function automatically identify optimized number clusters. function return vector cluster labels. Internally converted numeric labels.","code":"register_clustering_methods(     method1 = function(mat, ...) ...,     method2 = function(mat, ...) ...,     ... )"},{"path":"/articles/simplifyEnrichment_intro.html","id":"examples","dir":"Articles","previous_headings":"","what":"Examples","title":"Simplify Functional Enrichment Results","text":"following examples benchmarking manuscript: Examples simplifyEnrichment. Compare different similarity measures functional terms. Compare different partitioning methods binary cut clustering.","code":""},{"path":"/articles/simplifyEnrichment_intro.html","id":"apply-to-multiple-lists-of-go-ids","dir":"Articles","previous_headings":"","what":"Apply to multiple lists of GO IDs","title":"Simplify Functional Enrichment Results","text":"always common users multiple lists GO enrichment results (e.g. multiple groups genes) want compare significant terms different lists, e.g. see biological functions specific certain list. function simplifyGOFromMultipleLists() package helps type analysis. input data simplifyGOFromMultipleLists() (argument lt) can three types formats: list numeric vectors adjusted p-values vector GO IDs names. data frame. column GO IDs can specified go_id_column argument column adjusted p-values can specified padj_column argument. two columns specified, automatically identified. GO ID column found checking whether column contains GO IDs. adjusted p-value column found comparing column names data frame see whether might column adjusted p-values. two columns used construct numeric vector GO IDs names. list character vectors GO IDs. case, character vector changed numeric vector values take 1 original GO IDs used names vector. GO enrichment results directly upstream analysis, e.g. package clusterProfiler similar packages, results probably represented list data frames, thus, first demonstrate usage list data frames. function functional_enrichment() cola package applies functional enrichment different groups signature genes consensus clustering. function internally uses clusterProfiler returns list data frames: default, simplifyGOFromMultipleLists() automatically identifies columns contain GO IDs adjusted p-values, directly send lt simplifyGOFromMultipleLists(). additionally set padj_cutoff 0.001 default cutoff 0.01, many GO IDs save running time, set strict cutoff.  Next demonstrate two data types simplifyGOFromMultipleLists(). usages straightforward. first list numeric vectors: second list character vectors GO IDs: process analysis follows. Let’s assume \\(n\\) GO lists, first construct global matrix columns correspond \\(n\\) GO lists rows correspond “union” GO IDs \\(n\\) lists. value ith GO ID jth list taken corresponding numeric vector lt. jth vector lt contain ith GO ID, value defined default argument taken (e.g. cases numeric values adjusted p-values, thus default set 1). Let’s call matrix \\(M_0\\). Next step filter \\(M_0\\) take subset GO IDs interest. define proper function via argument filter remove GO IDs important analysis. Function filter applied every row \\(M_0\\) filter function needs return logical value decide whether keep remove current GO ID. example, values lt adjusted p-values, filter function can set function(x) (x < padj_cutoff) GO ID kept long signfiicant least one list. filtering, let’s call filtered matrix \\(M_1\\). GO IDs \\(M_1\\) (row names \\(M_1\\)) used clustering. heatmap \\(M_1\\) attached left GO similarity heatmap group-specific (list-specific) patterns can easily observed corresponded GO functions. Argument heatmap_param controls several parameters heatmap \\(M_1\\): transform: self-defined function transform data heatmap visualization. typical case transform adjusted p-values -log10(x). breaks: Break values color interpolation. col: corresponding values breaks. labels: corresponding labels legend. name: Legend title.","code":"# perform functional enrichment on the signatures genes from cola anlaysis  library(cola) data(golub_cola)  res = golub_cola[\"ATC:skmeans\"]  library(hu6800.db) x = hu6800ENTREZID mapped_probes = mappedkeys(x) id_mapping = unlist(as.list(x[mapped_probes]))  lt = functional_enrichment(res, k = 3, id_mapping = id_mapping) ## - 2058/4116 significant genes are taken from 3-group comparisons ## - on k-means group 1/4, 531 genes ##   - 478/531 (90%) genes left after id mapping ##   - gene set enrichment, GO:BP ## - on k-means group 2/4, 811 genes ##   - 640/811 (78.9%) genes left after id mapping ##   - gene set enrichment, GO:BP ## - on k-means group 3/4, 315 genes ##   - 276/315 (87.6%) genes left after id mapping ##   - gene set enrichment, GO:BP ## - on k-means group 4/4, 401 genes ##   - 374/401 (93.3%) genes left after id mapping ##   - gene set enrichment, GO:BP names(lt) ## [1] \"BP_km1\" \"BP_km2\" \"BP_km3\" \"BP_km4\" head(lt[[1]][, 1:7]) ##                    ID                              Description GeneRatio ## GO:0006974 GO:0006974 cellular response to DNA damage stimulus    77/471 ## GO:0006281 GO:0006281                               DNA repair    61/471 ## GO:0000278 GO:0000278                       mitotic cell cycle    78/471 ## GO:1903047 GO:1903047               mitotic cell cycle process    70/471 ## GO:0051276 GO:0051276                  chromosome organization    58/471 ## GO:0006260 GO:0006260                          DNA replication    38/471 ##              BgRatio       pvalue     p.adjust       qvalue ## GO:0006974 871/18614 3.252635e-22 1.545002e-18 1.174030e-18 ## GO:0006281 587/18614 3.683205e-21 8.220452e-18 6.246633e-18 ## GO:0000278 933/18614 5.191864e-21 8.220452e-18 6.246633e-18 ## GO:1903047 777/18614 1.148628e-20 1.363995e-17 1.036485e-17 ## GO:0051276 626/18614 8.913192e-18 8.467532e-15 6.434386e-15 ## GO:0006260 278/18614 1.862901e-17 1.474797e-14 1.120682e-14 simplifyGOFromMultipleLists(lt, padj_cutoff = 0.001) lt2 = lapply(lt, function(x) structure(x$p.adjust, names = x$ID)) simplifyGOFromMultipleLists(lt2, padj_cutoff = 0.001) lt3 = lapply(lt, function(x) x$ID[x$p.adjust < 0.001]) simplifyGOFromMultipleLists(lt3)"},{"path":"/articles/simplifyEnrichment_intro.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"Simplify Functional Enrichment Results","text":"","code":"sessionInfo() ## R version 4.3.3 (2024-02-29) ## Platform: x86_64-apple-darwin20 (64-bit) ## Running under: macOS Sonoma 14.6.1 ##  ## Matrix products: default ## BLAS:   /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRblas.0.dylib  ## LAPACK: /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0 ##  ## Random number generation: ##  RNG:     L'Ecuyer-CMRG  ##  Normal:  Inversion  ##  Sample:  Rejection  ##   ## locale: ## [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8 ##  ## time zone: Europe/Berlin ## tzcode source: internal ##  ## attached base packages: ## [1] stats4    stats     graphics  grDevices utils     datasets  methods   ## [8] base      ##  ## other attached packages: ##  [1] hu6800.db_3.13.0          org.Hs.eg.db_3.17.0       ##  [3] AnnotationDbi_1.62.2      IRanges_2.36.0            ##  [5] S4Vectors_0.40.2          Biobase_2.60.0            ##  [7] BiocGenerics_0.48.1       cola_2.6.0                ##  [9] simplifyEnrichment_1.99.0 knitr_1.45                ##  ## loaded via a namespace (and not attached): ##   [1] splines_4.3.3           later_1.3.2             ggplotify_0.1.2         ##   [4] bitops_1.0-7            tibble_3.2.1            polyclip_1.10-6         ##   [7] XML_3.99-0.16.1         lifecycle_1.0.4         doParallel_1.0.17       ##  [10] NLP_0.2-1               lattice_0.22-5          prabclus_2.3-3          ##  [13] MASS_7.3-60.0.1         magrittr_2.0.3          sass_0.4.9              ##  [16] rmarkdown_2.26          jquerylib_0.1.4         yaml_2.3.8              ##  [19] httpuv_1.6.15           doRNG_1.8.6             flexmix_2.3-19          ##  [22] cowplot_1.1.3           DBI_1.2.2               RColorBrewer_1.1-3      ##  [25] eulerr_7.0.2            zlibbioc_1.46.0         expm_0.999-9            ##  [28] purrr_1.0.2             ggraph_2.2.1            RCurl_1.98-1.14         ##  [31] yulab.utils_0.1.4       nnet_7.3-19             tweenr_2.0.3            ##  [34] circlize_0.4.16         GenomeInfoDbData_1.2.10 enrichplot_1.20.3       ##  [37] ggrepel_0.9.5           tm_0.7-13               irlba_2.3.5.1           ##  [40] tidytree_0.4.6          genefilter_1.82.1       annotate_1.78.0         ##  [43] brew_1.0-10             commonmark_1.9.1        pkgdown_2.0.9           ##  [46] codetools_0.2-19        ggforce_0.4.2           DOSE_3.26.2             ##  [49] xml2_1.3.6              tidyselect_1.2.1        shape_1.4.6.1           ##  [52] aplot_0.2.2             farver_2.1.1            viridis_0.6.5           ##  [55] matrixStats_1.3.0       dynamicTreeCut_1.63-1   jsonlite_1.8.8          ##  [58] GetoptLong_1.0.5        tidygraph_1.3.1         survival_3.5-8          ##  [61] iterators_1.0.14        systemfonts_1.0.6       foreach_1.5.2           ##  [64] dbscan_1.1-12           tools_4.3.3             treeio_1.24.3           ##  [67] ragg_1.3.1              Rcpp_1.0.12             glue_1.7.0              ##  [70] gridExtra_2.3           xfun_0.43               qvalue_2.32.0           ##  [73] flexclust_1.4-2         MatrixGenerics_1.12.3   GenomeInfoDb_1.36.4     ##  [76] dplyr_1.1.4             withr_3.0.0             fastmap_1.1.1           ##  [79] fansi_1.0.6             digest_0.6.35           gridGraphics_0.5-1      ##  [82] R6_2.5.1                mime_0.12               microbenchmark_1.4.10   ##  [85] textshaping_0.3.7       colorspace_2.1-0        GO.db_3.17.0            ##  [88] Cairo_1.6-2             markdown_1.12           RSQLite_2.3.6           ##  [91] diptest_0.77-1          tidyr_1.3.1             utf8_1.2.4              ##  [94] generics_0.1.3          data.table_1.15.4       robustbase_0.99-2       ##  [97] class_7.3-22            graphlayouts_1.1.1      httr_1.4.7              ## [100] htmlwidgets_1.6.4       scatterpie_0.2.2        scatterplot3d_0.3-44    ## [103] MCL_1.0                 pkgconfig_2.0.3         gtable_0.3.5            ## [106] modeltools_0.2-23       blob_1.2.4              ComplexHeatmap_2.18.0   ## [109] impute_1.74.1           XVector_0.40.0          shadowtext_0.1.3        ## [112] clusterProfiler_4.8.3   htmltools_0.5.8.1       fgsea_1.26.0            ## [115] clue_0.3-65             scales_1.3.0            png_0.1-8               ## [118] ggfun_0.1.4             reshape2_1.4.4          rjson_0.2.21            ## [121] nlme_3.1-164            cachem_1.0.8            GlobalOptions_0.1.2     ## [124] Polychrome_1.5.1        stringr_1.5.1           parallel_4.3.3          ## [127] HDO.db_0.99.1           desc_1.4.3              pillar_1.9.0            ## [130] grid_4.3.3              vctrs_0.6.5             slam_0.1-50             ## [133] promises_1.3.0          xtable_1.8-4            cluster_2.1.6           ## [136] evaluate_0.23           magick_2.8.3            cli_3.6.2               ## [139] compiler_4.3.3          rlang_1.1.3             crayon_1.5.2            ## [142] rngtools_1.5.2          simona_1.3.12           labeling_0.4.3          ## [145] mclust_6.1.1            skmeans_0.2-16          plyr_1.8.9              ## [148] fs_1.6.4                stringi_1.8.4           viridisLite_0.4.2       ## [151] BiocParallel_1.34.2     munsell_0.5.1           Biostrings_2.68.1       ## [154] lazyeval_0.2.2          GOSemSim_2.26.1         Matrix_1.6-5            ## [157] patchwork_1.2.0         bit64_4.0.5             ggplot2_3.5.1           ## [160] KEGGREST_1.40.1         fpc_2.2-12              shiny_1.8.1.1           ## [163] highr_0.10              apcluster_1.4.13        kernlab_0.9-32          ## [166] gridtext_0.1.5          igraph_2.0.3            memoise_2.0.1           ## [169] bslib_0.7.0             ggtree_3.8.2            fastmatch_1.1-4         ## [172] DEoptimR_1.1-3          bit_4.0.5               downloader_0.4          ## [175] gson_0.1.0              ape_5.8"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Zuguang Gu. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Gu, Z. (2022) simplifyEnrichment: R/Bioconductor package Clustering Visualizing Functional Enrichment Results. Genomics, Proteomics & Bioinformatics.","code":"@Article{,   title = {simplifyEnrichment: an R/Bioconductor package for Clustering and Visualizing Functional Enrichment Results},   author = {Zuguang Gu and Daniel Huebschmann},   journal = {Genomics, Proteomics & Bioinformatics},   year = {2021},   doi = {https://doi.org/10.1016/j.gpb.2022.04.008}, }"},{"path":[]},{"path":"/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"Simplify Functional Enrichment Results","text":"new method (binary cut) proposed efficiently cluster functional terms (e.g. GO terms) groups semantic similarity matrix. Summaries functional terms cluster visualized word clouds.","code":""},{"path":"/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Simplify Functional Enrichment Results","text":"Zuguang Gu, et al., simplifyEnrichment: R/Bioconductor package Clustering Visualizing Functional Enrichment Results, Genomics, Proteomics & Bioinformatics 2022. https://doi.org/10.1016/j.gpb.2022.04.008.","code":""},{"path":"/index.html","id":"install","dir":"","previous_headings":"","what":"Install","title":"Simplify Functional Enrichment Results","text":"simplifyEnrichment available Bioconductor, can install : want try latest version, install directly GitHub:","code":"if (!requireNamespace(\"BiocManager\", quietly=TRUE))     install.packages(\"BiocManager\") BiocManager::install(\"simplifyEnrichment\") library(devtools) install_github(\"jokergoo/simplifyEnrichment\")"},{"path":"/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Simplify Functional Enrichment Results","text":"example, first generate list random GO IDs. generate GO similarity matrix, split GO terms clusters visualize .","code":"library(simplifyEnrichment) set.seed(888) go_id = random_GO(500) head(go_id) # [1] \"GO:0003283\" \"GO:0060032\" \"GO:0031334\" \"GO:0097476\" \"GO:1901222\" # [6] \"GO:0018216\" mat = GO_similarity(go_id) simplifyGO(mat)"},{"path":"/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Simplify Functional Enrichment Results","text":"MIT @ Zuguang Gu","code":""},{"path":"/reference/GO_similarity.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Gene Ontology (GO) semantic similarity matrix — GO_similarity","title":"Calculate Gene Ontology (GO) semantic similarity matrix — GO_similarity","text":"Calculate Gene Ontology (GO) semantic similarity matrix","code":""},{"path":"/reference/GO_similarity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Gene Ontology (GO) semantic similarity matrix — GO_similarity","text":"","code":"GO_similarity(   go_id,   ont = NULL,   db = \"org.Hs.eg.db\",   measure = \"Sim_XGraSM_2013\" )  guess_ont(go_id, db = \"org.Hs.eg.db\")  random_GO(n, ont = c(\"BP\", \"CC\", \"MF\"), db = \"org.Hs.eg.db\")"},{"path":"/reference/GO_similarity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Gene Ontology (GO) semantic similarity matrix — GO_similarity","text":"go_id vector GO IDs. ont Sub-ontology GO. Value one \"BP\", \"CC\" \"MF\". specified, function automatically identifies random sampling 10 IDs go_id (see guess_ont()). db Annotation database. OrgDb package name https://bioconductor.org/packages/release/BiocViews.html#___OrgDb. value can also directly OrgDb object. measure Semantic measure GO similarity, pass simona::term_sim(). valid values simona::all_term_sim_methods(). n Number GO IDs.","code":""},{"path":"/reference/GO_similarity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Gene Ontology (GO) semantic similarity matrix — GO_similarity","text":"GO_similarity() returns symmetric matrix. guess_ont() returns single character scalar \"BP\", \"CC\" \"MF\". one ontologies detected. returns NULL. random_GO() returns vector GO IDs.","code":""},{"path":"/reference/GO_similarity.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Gene Ontology (GO) semantic similarity matrix — GO_similarity","text":"default similarity method \"Sim_XGraSM_2013\". Since semantic similarities calculated based gene annotations GO terms, suggest users also try following methods: \"Sim_Lin_1998\" \"Sim_Resnik_1999\" \"Sim_Relevance_2006\" \"Sim_SimIC_2010\" \"Sim_XGraSM_2013\" \"Sim_EISI_2015\" \"Sim_AIC_2014\" \"Sim_Wang_2007\" \"Sim_GOGO_2018\" guess_ont(), 10 random GO IDs checked. random_GO(), GO terms gene annotations sampled.","code":""},{"path":"/reference/GO_similarity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Gene Ontology (GO) semantic similarity matrix — GO_similarity","text":"","code":"# \\donttest{ go_id = random_GO(100) #> relations: is_a, part_of, regulates, negatively_regulates, positively_regulates #>  #> IC_method: IC_annotation mat = GO_similarity(go_id) #> You haven't provided value for `ont`, guess it as `BP`. #> term_sim_method: Sim_XGraSM_2013 #> IC_method: IC_annotation # } # \\donttest{ go_id = random_GO(100) guess_ont(go_id) #> [1] \"BP\" # }"},{"path":"/reference/anno_word_cloud.html","id":null,"dir":"Reference","previous_headings":"","what":"Word cloud annotations — anno_word_cloud","title":"Word cloud annotations — anno_word_cloud","text":"Word cloud annotations","code":""},{"path":"/reference/anno_word_cloud.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Word cloud annotations — anno_word_cloud","text":"","code":"anno_word_cloud(   align_to,   term,   exclude_words = NULL,   max_words = 10,   word_cloud_grob_param = list(),   fontsize_range = c(4, 16),   value_range = NULL,   bg_gp = gpar(fill = \"#DDDDDD\", col = \"#AAAAAA\"),   side = c(\"right\", \"left\"),   add_new_line = FALSE,   count_words_param = list(),   ...,   return_gbl = FALSE )"},{"path":"/reference/anno_word_cloud.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Word cloud annotations — anno_word_cloud","text":"align_to align annotations heatmap. Similar ComplexHeatmap::anno_link, value align_to can list row indices categorical vector vector list corresponds word cloud. categorical vector, rows level correspond word cloud. align_to categorical vector term list, names term overlap levels align_to. align_to set categorical vector, normally value set row_split main heatmap row slice can correspond word cloud. term description text used constructing word clouds. value format align_to. align_to list, term also list. case, length vectors term necessarily align_to. E.g. length(term[[1]]) necessarily equal length(align_to[[1]]. align_to categorical vector, term also character vector length align_to. make genrall, align_to list, term can also list data frames first column contains keywords second column contains numeric values mapped font sizes word clouds. exclude_words words excluced construcing word cloud. max_words Maximal number words visualized word cloud. word_cloud_grob_param list graphics parameters passed word_cloud_grob. fontsize_range range font size. value numeric vector length two. font size interpolation linear. value_range range values map font sizes. bg_gp Graphics parameters controlling background. side Side annotation relative heatmap. add_new_line Whether add new line every word? TRUE, word separated line. count_words_param list parameters passed count_words. ... parameters. return_gbl Internally used.","code":""},{"path":"/reference/anno_word_cloud.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Word cloud annotations — anno_word_cloud","text":"word cloud annotation constructed ComplexHeatmap::anno_link. annotation failed construct keyword found, function returns ComplexHeatmap::anno_empty 1px width. English stop words, punctuation numbers removed default counting words. specific stop words might coincide gene pathway names, numbers genes names might meaningful recommended adjust behaviour passing appropriate arguments count_words function using count_words_param.","code":""},{"path":"/reference/anno_word_cloud.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Word cloud annotations — anno_word_cloud","text":"","code":"gm = readRDS(system.file(\"extdata\", \"random_GO_BP_sim_mat.rds\", package = \"simplifyEnrichment\")) go_id = rownames(gm) go_term = AnnotationDbi::select(GO.db::GO.db, keys = go_id, columns = \"TERM\")$TERM #> 'select()' returned 1:1 mapping between keys and columns  split = sample(letters[1:4], 100, replace = TRUE) align_to = split(1:100, split) term = lapply(letters[1:4], function(x) sample(go_term, sample(100:400, 1))) names(term) = letters[1:4]  require(ComplexHeatmap) #> Loading required package: ComplexHeatmap #> Loading required package: grid #> ======================================== #> ComplexHeatmap version 2.18.0 #> Bioconductor page: http://bioconductor.org/packages/ComplexHeatmap/ #> Github page: https://github.com/jokergoo/ComplexHeatmap #> Documentation: http://jokergoo.github.io/ComplexHeatmap-reference #>  #> If you use it in published research, please cite either one: #> - Gu, Z. Complex Heatmap Visualization. iMeta 2022. #> - Gu, Z. Complex heatmaps reveal patterns and correlations in multidimensional  #>     genomic data. Bioinformatics 2016. #>  #>  #> The new InteractiveComplexHeatmap package can directly export static  #> complex heatmaps into an interactive Shiny app with zero effort. Have a try! #>  #> This message can be suppressed by: #>   suppressPackageStartupMessages(library(ComplexHeatmap)) #> ======================================== mat = matrix(rnorm(100*10), nrow = 100) Heatmap(mat, cluster_rows = FALSE, row_split = split,    right_annotation = rowAnnotation(foo = anno_word_cloud(align_to, term)))"},{"path":"/reference/anno_word_cloud_from_GO.html","id":null,"dir":"Reference","previous_headings":"","what":"Word cloud annotations from GO — anno_word_cloud_from_GO","title":"Word cloud annotations from GO — anno_word_cloud_from_GO","text":"Word cloud annotations GO","code":""},{"path":"/reference/anno_word_cloud_from_GO.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Word cloud annotations from GO — anno_word_cloud_from_GO","text":"","code":"anno_word_cloud_from_GO(   align_to,   go_id,   stat = c(\"pvalue\", \"count\"),   min_stat = ifelse(stat == \"count\", 5, 0.05),   term = NULL,   exclude_words = NULL,   ... )"},{"path":"/reference/anno_word_cloud_from_GO.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Word cloud annotations from GO — anno_word_cloud_from_GO","text":"align_to format anno_word_cloud. go_id value format align_to. go_id vector, length align_to, go_id list, note, e.g. length(go_id[[1]]) necessarily equal length(align_to[[1]]. align_to categorical vector go_id list, names go_id overlap levels align_to. stat type value map font sizes keywords. two possible values. \"pvalue\": enrichment applied keywords -log10(p-value) used map font size; \"count\": simply word frequency keywords. min_stat Minimal value stat selecting keywords. term Alternatively GO description can set via term argument. format anno_word_cloud. exclude_words words excluced construcing word cloud. words internally exclucded: c(\"via\", \"protein\", \"factor\", \"side\", \"type\", \"specific\"). ... arguments passed anno_word_cloud.","code":""},{"path":"/reference/area_above_ecdf.html","id":null,"dir":"Reference","previous_headings":"","what":"Area above the eCDF curve — area_above_ecdf","title":"Area above the eCDF curve — area_above_ecdf","text":"Area eCDF curve","code":""},{"path":"/reference/area_above_ecdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Area above the eCDF curve — area_above_ecdf","text":"","code":"area_above_ecdf(x)"},{"path":"/reference/area_above_ecdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Area above the eCDF curve — area_above_ecdf","text":"x vector similarity values.","code":""},{"path":"/reference/area_above_ecdf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Area above the eCDF curve — area_above_ecdf","text":"numeric value.","code":""},{"path":"/reference/area_above_ecdf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Area above the eCDF curve — area_above_ecdf","text":"Denote F(x) eCDF (empirical Cumulative Distribution Function) similarity vector x, function calculates area eCDF curve, 1 - \\int_0^1 F(x)dx.","code":""},{"path":"/reference/binary_cut.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster functional terms by recursively binary cutting the similarity matrix — plot_binary_cut","title":"Cluster functional terms by recursively binary cutting the similarity matrix — plot_binary_cut","text":"Cluster functional terms recursively binary cutting similarity matrix","code":""},{"path":"/reference/binary_cut.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster functional terms by recursively binary cutting the similarity matrix — plot_binary_cut","text":"","code":"plot_binary_cut(   mat,   value_fun = area_above_ecdf,   cutoff = 0.85,   partition_fun = partition_by_pam,   dend = NULL,   dend_width = unit(3, \"cm\"),   depth = NULL,   show_heatmap_legend = TRUE,   ... )  binary_cut(   mat,   value_fun = area_above_ecdf,   partition_fun = partition_by_hclust,   cutoff = 0.85,   try_all_partition_fun = TRUE,   partial = nrow(mat) > 1500 )"},{"path":"/reference/binary_cut.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster functional terms by recursively binary cutting the similarity matrix — plot_binary_cut","text":"mat similarity matrix. value_fun function calculates scores four submatrices node. cutoff cutoff splitting dendrogram. partition_fun function split node two groups. Pre-defined functions package partition_by_kmeanspp(), partition_by_pam()  partition_by_hclust(). dend dendrogram object, used internally. dend_width Width dendrogram plot. depth Depth recursive binary cut process. show_heatmap_legend Whether show heatmap legend. ... arguments. try_all_partition_fun Different partition_fun may give different clusterings. vaule try_all_partition_fun set TRUE, similarity matrix clustered three partitioning method: partition_by_pam(), partition_by_kmeanspp() partition_by_hclust(). clustering highest difference score finally selected final clustering. partial Whether generate complete clustering clustering stops sub-matrices split anymore.","code":""},{"path":"/reference/binary_cut.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster functional terms by recursively binary cutting the similarity matrix — plot_binary_cut","text":"binary_cut() returns vector numeric cluster labels.","code":""},{"path":"/reference/binary_cut.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cluster functional terms by recursively binary cutting the similarity matrix — plot_binary_cut","text":"functions perform clustering executed, simplifyGO() binary_cut(), dendrogram temporarily saved plot_binary_cut() directly uses dendrogram.","code":""},{"path":"/reference/binary_cut.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cluster functional terms by recursively binary cutting the similarity matrix — plot_binary_cut","text":"","code":"# \\donttest{ mat = readRDS(system.file(\"extdata\", \"random_GO_BP_sim_mat.rds\",      package = \"simplifyEnrichment\")) plot_binary_cut(mat, depth = 1) #> create a new dendrogram.  plot_binary_cut(mat, depth = 2) #> use the cached dendrogram.  plot_binary_cut(mat) #> use the cached dendrogram.  # } mat = readRDS(system.file(\"extdata\", \"random_GO_BP_sim_mat.rds\",     package = \"simplifyEnrichment\")) binary_cut(mat) #>   [1]  1  2  3  4  5  4  4  4  1  3  3  5  1  5  1  4  1  4  5  4  5  1  4  3  6 #>  [26]  3  7  4  3  1  1  3  8  7  3  3  5  1  4  4  5  2  4  9  5  1  1  7  3  7 #>  [51]  5  3 10  7  1  7  3 10  3  3  7  1  5  5  3  1  1  1  1  3  1  4 11  3  1 #>  [76]  3  4  7  3  3  1  5  4  6  3  3  1  5  4  5  7  3  3  4  5  3  1  1  4  6 #> [101]  4  3  4  4  1  4  3  5  3  7  3  1  3  3  3  1  1  1  9  4  4 12  3  1  1 #> [126]  1  1  5  4  1  4  1  3  5  5  5  1  5  3  5  5  5  1  3  5  5 13  1  2  4 #> [151] 12  3  7  1  3  5  6  1  4  5  1  5  1  1  5  3  3  4  1  1  3  3  3  1  4 #> [176]  4  1  3  4  3  3 14  5  4  4  3  1  3  5  3  5  3  3  3  1  1  1  5  4  3 #> [201]  2  5  4  4 10  3  1  1  3  3  1  2  3  3  3  4  5  3  4  3  4  6  6  4  7 #> [226]  4  5  5  1  1  3  1  6 12  7  7  5  5  3  3  7  3  1  4  1  1  5  6  3  5 #> [251]  5  1 15  1  3 11  4  1  5 13  3  1  7  3  1  5  1  3  5  5  3  6  1  5  3 #> [276] 11  1  2  3  4  5 13  1  1 10  3  5  3  3  3  7  4  5  3  3  4  1  1  4  7 #> [301]  3  2  4  5  3  3  5  3  1  3  2  5  2  3  3  1  1  5  5  4 11  1  1  5  3 #> [326]  3  1  4  5  1  1  1  1  7  3  2  3  2  5  3  5  1 13  3  3  4  3  1  4  6 #> [351]  4  7  1  3  1  4  7  3  5  3  1  2 11  4  3  3  1  1  1  5  7  7  1  1  3 #> [376]  5  3  7  3 10  1  3  1  7  3  1  3 11  3 16  4  6  3  1  3  7  6  1  5  4 #> [401]  5  3  1  3  3  5  3  3  7  4  5  1  7  5  7  3  1 12  3  3 10  1  1  4  3 #> [426]  1  3 13  1  3  3  1  1  5  3  3  1  1  1  1 17  5  1  3  7  3  1  5  1  5 #> [451]  7  3  4  5  4  4  1  1  3  5  7 11  4  4  5  3  4  4  1  1  3  5 12  5  3 #> [476]  3  3  3  5 14  3  3  3  4  1 11  5  1  3  3  1  5  3  1  3 18  7  5  3  1"},{"path":"/reference/cluster_methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Configure clustering methods — register_clustering_methods","title":"Configure clustering methods — register_clustering_methods","text":"Configure clustering methods","code":""},{"path":"/reference/cluster_methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Configure clustering methods — register_clustering_methods","text":"","code":"register_clustering_methods(...)  all_clustering_methods()  remove_clustering_methods(method)  reset_clustering_methods()"},{"path":"/reference/cluster_methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Configure clustering methods — register_clustering_methods","text":"... named list clustering functions, see Details. method vector method names.","code":""},{"path":"/reference/cluster_methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Configure clustering methods — register_clustering_methods","text":"all_clustering_methods() returns vector clustering method names.","code":""},{"path":"/reference/cluster_methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Configure clustering methods — register_clustering_methods","text":"user-defined functions accept least one argument input matrix. second optional argument always ... parameters clustering function can passed control argument cluster_terms(), simplifyGO() simplifyEnrichment(). users forget add ..., added internally. Please note, user-defined function automatically identify optimized number clusters. function return vector cluster labels. Internally converted numeric labels. default clustering methods : kmeans see cluster_by_kmeans(). dynamicTreeCut see cluster_by_dynamicTreeCut(). mclust see cluster_by_mclust(). apcluster see cluster_by_apcluster(). hdbscan see cluster_by_hdbscan(). fast_greedy see cluster_by_fast_greedy(). louvain see cluster_by_louvain(). walktrap see cluster_by_walktrap(). MCL see cluster_by_MCL(). binary_cut see binary_cut().","code":""},{"path":"/reference/cluster_methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Configure clustering methods — register_clustering_methods","text":"","code":"register_clustering_methods(     # assume there are 5 groups     random = function(mat, ...) sample(5, nrow(mat), replace = TRUE) ) all_clustering_methods() #>  [1] \"binary_cut\"     \"kmeans\"         \"pam\"            \"dynamicTreeCut\" #>  [5] \"mclust\"         \"apcluster\"      \"hdbscan\"        \"fast_greedy\"    #>  [9] \"louvain\"        \"walktrap\"       \"MCL\"            \"random\"         remove_clustering_methods(\"random\") all_clustering_methods() #>  [1] \"binary_cut\"     \"kmeans\"         \"pam\"            \"dynamicTreeCut\" #>  [5] \"mclust\"         \"apcluster\"      \"hdbscan\"        \"fast_greedy\"    #>  [9] \"louvain\"        \"walktrap\"       \"MCL\"            remove_clustering_methods(c(\"kmeans\", \"mclust\")) all_clustering_methods() #> [1] \"binary_cut\"     \"pam\"            \"dynamicTreeCut\" \"apcluster\"      #> [5] \"hdbscan\"        \"fast_greedy\"    \"louvain\"        \"walktrap\"       #> [9] \"MCL\"            reset_clustering_methods() all_clustering_methods() #>  [1] \"kmeans\"         \"pam\"            \"dynamicTreeCut\" \"mclust\"         #>  [5] \"apcluster\"      \"hdbscan\"        \"fast_greedy\"    \"louvain\"        #>  [9] \"walktrap\"       \"MCL\"            \"binary_cut\""},{"path":"/reference/cluster_terms.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster terms based on their similarity matrix — cluster_terms","title":"Cluster terms based on their similarity matrix — cluster_terms","text":"Cluster terms based similarity matrix","code":""},{"path":"/reference/cluster_terms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster terms based on their similarity matrix — cluster_terms","text":"","code":"cluster_terms(   mat,   method = \"binary_cut\",   control = list(),   verbose = se_opt$verbose )  cluster_by_kmeans(mat, max_k = max(2, min(round(nrow(mat)/5), 100)), ...)  cluster_by_pam(mat, max_k = max(2, min(round(nrow(mat)/10), 100)), ...)  cluster_by_dynamicTreeCut(mat, minClusterSize = 5, ...)  cluster_by_fast_greedy(mat, ...)  cluster_by_leading_eigen(mat, ...)  cluster_by_louvain(mat, ...)  cluster_by_walktrap(mat, ...)  cluster_by_mclust(mat, G = seq_len(max(2, min(round(nrow(mat)/5), 100))), ...)  cluster_by_apcluster(mat, s = apcluster::negDistMat(r = 2), ...)  cluster_by_hdbscan(mat, minPts = 5, ...)  cluster_by_MCL(mat, addLoops = TRUE, ...)"},{"path":"/reference/cluster_terms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster terms based on their similarity matrix — cluster_terms","text":"mat similarity matrix. method clustering methods. Value all_clustering_methods(). control list parameters passed corresponding clustering function. verbose Whether print messages. max_k Maximal k k-means/PAM clustering. K-means/PAM clustering applied k = 2 k = max_k. ... arguments. minClusterSize Minimal number objects cluster. Pass dynamicTreeCut::cutreeDynamic(). G Passed G argument mclust::Mclust() number clusters. s Passed s argument apcluster::apcluster(). minPts Passed minPts argument dbscan::hdbscan(). addLoops Passed addLoops argument MCL::mcl().","code":""},{"path":"/reference/cluster_terms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster terms based on their similarity matrix — cluster_terms","text":"vector numeric cluster labels.","code":""},{"path":"/reference/cluster_terms.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cluster terms based on their similarity matrix — cluster_terms","text":"New clustering methods can registered register_clustering_methods(). Please note better directly use cluster_terms() clustering individual cluster_by_* functions cluster_terms() additional cluster label adjustment. default, following clustering methods corresponding clustering functions: kmeans see cluster_by_kmeans(). dynamicTreeCut see cluster_by_dynamicTreeCut(). mclust see cluster_by_mclust(). apcluster see cluster_by_apcluster(). hdbscan see cluster_by_hdbscan(). fast_greedy see cluster_by_fast_greedy(). louvain see cluster_by_louvain(). walktrap see cluster_by_walktrap(). MCL see cluster_by_MCL(). binary_cut see binary_cut(). additional argument individual clustering functions can set control argument cluster_terms(). cluster_by_kmeans(): best k k-means clustering determined according \"elbow\" \"knee\" method distribution within-cluster sum squares (WSS) k. arguments passed ... stats::kmeans(). cluster_by_pam(): PAM applied fpc::pamk() can automatically select best k. arguments passed ... fpc::pamk(). cluster_by_dynamicTreeCut(): arguments passed ... dynamicTreeCut::cutreeDynamic(). cluster_by_fast_greedy(): arguments passed ... igraph::cluster_fast_greedy(). cluster_by_leading_eigen(): arguments passed ... igraph::cluster_leading_eigen(). cluster_by_louvain(): arguments passed ... igraph::cluster_louvain(). cluster_by_walktrap(): arguments passed ... igraph::cluster_walktrap(). cluster_by_mclust(): arguments passed ... mclust::Mclust(). cluster_by_apcluster(): arguments passed ... apcluster::apcluster(). cluster_by_hdbscan(): arguments passed ... dbscan::hdbscan(). cluster_by_MCL(): arguments passed ... MCL::mcl().","code":""},{"path":"/reference/cmp_make_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply various clustering methods — cmp_make_clusters","title":"Apply various clustering methods — cmp_make_clusters","text":"Apply various clustering methods","code":""},{"path":"/reference/cmp_make_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply various clustering methods — cmp_make_clusters","text":"","code":"cmp_make_clusters(   mat,   method = setdiff(all_clustering_methods(), \"mclust\"),   verbose = TRUE )"},{"path":"/reference/cmp_make_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply various clustering methods — cmp_make_clusters","text":"mat similarity matrix. method methods compare. available methods all_clustering_methods. value takes available methods. default mclust excluded long runtime. verbose Whether print messages. Ddetails function compares following default clustering methods default: -kmeans see cluster_by_kmeans. -pam see cluster_by_pam. -dynamicTreeCut see cluster_by_dynamicTreeCut. -mclust see cluster_by_mclust. default included. -apcluster see cluster_by_apcluster. -hdbscan see cluster_by_hdbscan. -fast_greedy see cluster_by_fast_greedy. -louvain see cluster_by_louvain. -walktrap see cluster_by_walktrap. -MCL see cluster_by_MCL. -binary_cut see binary_cut. Also user-defined methods all_clustering_methods also compared.","code":""},{"path":"/reference/cmp_make_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply various clustering methods — cmp_make_clusters","text":"list cluster label vectors different clustering methods.","code":""},{"path":"/reference/cmp_make_clusters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply various clustering methods — cmp_make_clusters","text":"","code":"# \\donttest{ mat = readRDS(system.file(\"extdata\", \"random_GO_BP_sim_mat.rds\",     package = \"simplifyEnrichment\")) clt = cmp_make_clusters(mat) #> Cluster 500 terms by 'kmeans'... #>  16 clusters, used 4.146869 secs. #> Cluster 500 terms by 'pam'... #>  5 clusters, used 20.6156 secs. #> Cluster 500 terms by 'dynamicTreeCut'... #>  60 clusters, used 0.143589 secs. #> Cluster 500 terms by 'apcluster'... #>  41 clusters, used 1.058974 secs. #> Cluster 500 terms by 'hdbscan'... #>  14 clusters, used 0.173619 secs. #> Cluster 500 terms by 'fast_greedy'... #>  6 clusters, used 0.073627 secs. #> Cluster 500 terms by 'louvain'... #>  6 clusters, used 0.0734272 secs. #> Cluster 500 terms by 'walktrap'... #>  6 clusters, used 0.7433069 secs. #> Cluster 500 terms by 'MCL'... #>  6 clusters, used 1.747188 secs. #> Cluster 500 terms by 'binary_cut'... #>  19 clusters, used 4.274761 secs. # }"},{"path":"/reference/cmp_make_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Make plots for comparing clustering methods — cmp_make_plot","title":"Make plots for comparing clustering methods — cmp_make_plot","text":"Make plots comparing clustering methods","code":""},{"path":"/reference/cmp_make_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make plots for comparing clustering methods — cmp_make_plot","text":"","code":"cmp_make_plot(mat, clt, plot_type = c(\"mixed\", \"heatmap\"), nrow = 3)"},{"path":"/reference/cmp_make_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make plots for comparing clustering methods — cmp_make_plot","text":"mat similarity matrix. clt list clusterings cmp_make_clusters. plot_type type plots make. See Details. nrow Number rows layout plot_type set heatmap.","code":""},{"path":"/reference/cmp_make_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make plots for comparing clustering methods — cmp_make_plot","text":"value returned.","code":""},{"path":"/reference/cmp_make_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make plots for comparing clustering methods — cmp_make_plot","text":"plot_type default value mixed, figure three panels generated: heatmap similarity matrix different classifications row annotations. heatmap pair-wise concordance classifications every two clustering methods. Barplots difference scores method (calculated difference_score), number clusters (total clusters clusters size >= 5) mean similarity terms clusters. plot_type heatmap. heatmaps similarity matrix clusterings different methods. last panel table number clusters different clusterings.","code":""},{"path":"/reference/cmp_make_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make plots for comparing clustering methods — cmp_make_plot","text":"","code":"# \\donttest{ mat = readRDS(system.file(\"extdata\", \"random_GO_BP_sim_mat.rds\",     package = \"simplifyEnrichment\")) clt = cmp_make_clusters(mat) #> Cluster 500 terms by 'kmeans'... #>  21 clusters, used 3.146765 secs. #> Cluster 500 terms by 'pam'... #>  5 clusters, used 20.66386 secs. #> Cluster 500 terms by 'dynamicTreeCut'... #>  60 clusters, used 0.129586 secs. #> Cluster 500 terms by 'apcluster'... #>  41 clusters, used 0.8815429 secs. #> Cluster 500 terms by 'hdbscan'... #>  14 clusters, used 0.1694231 secs. #> Cluster 500 terms by 'fast_greedy'... #>  6 clusters, used 0.07081795 secs. #> Cluster 500 terms by 'louvain'... #>  6 clusters, used 0.070678 secs. #> Cluster 500 terms by 'walktrap'... #>  6 clusters, used 0.2896349 secs. #> Cluster 500 terms by 'MCL'... #>  6 clusters, used 1.792966 secs. #> Cluster 500 terms by 'binary_cut'... #>  19 clusters, used 4.505744 secs. cmp_make_plot(mat, clt)  cmp_make_plot(mat, clt, plot_type = \"heatmap\")  # }"},{"path":"/reference/compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare clustering methods — cmp_make_clusters","title":"Compare clustering methods — cmp_make_clusters","text":"Compare clustering methods","code":""},{"path":"/reference/compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare clustering methods — cmp_make_clusters","text":"","code":"cmp_make_clusters(   mat,   method = setdiff(all_clustering_methods(), \"mclust\"),   verbose = TRUE )  cmp_make_plot(mat, clt, plot_type = c(\"mixed\", \"heatmap\"), nrow = 3)  compare_clustering_methods(   mat,   method = setdiff(all_clustering_methods(), \"mclust\"),   plot_type = c(\"mixed\", \"heatmap\"),   nrow = 3,   verbose = TRUE )"},{"path":"/reference/compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare clustering methods — cmp_make_clusters","text":"mat similarity matrix. method methods compare. available methods all_clustering_methods(). value \"\" takes available methods. default \"mclust\" excluded long runtime. verbose Whether print messages. Ddetails function compares following default clustering methods default: -kmeans see cluster_by_kmeans. -pam see cluster_by_pam. -dynamicTreeCut see cluster_by_dynamicTreeCut. -mclust see cluster_by_mclust. default included. -apcluster see cluster_by_apcluster. -hdbscan see cluster_by_hdbscan. -fast_greedy see cluster_by_fast_greedy. -louvain see cluster_by_louvain. -walktrap see cluster_by_walktrap. -MCL see cluster_by_MCL. -binary_cut see binary_cut. Also user-defined methods all_clustering_methods also compared. clt list clusterings cmp_make_clusters(). plot_type type plots make. See Details. nrow Number rows layout plot_type set \"heatmap\".","code":""},{"path":"/reference/compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare clustering methods — cmp_make_clusters","text":"cmp_make_clusters() returns list cluster label vectors different clustering methods. cmp_make_plot() returns value. compare_clustering_methods() returns value.","code":""},{"path":"/reference/compare.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare clustering methods — cmp_make_clusters","text":"cmp_make_plot(), plot_type default value \"mixed\", figure three panels generated: heatmap similarity matrix different classifications row annotations. heatmap pair-wise concordance classifications every two clustering methods. Barplots difference scores method (calculated difference_score), number clusters (total clusters clusters size >= 5) mean similarity terms clusters. plot_type \"heatmap\". heatmaps similarity matrix clusterings different methods. last panel table number clusters different clusterings. compare_clustering_methods() basically wrapper function cmp_make_clusters() cmp_make_plot().","code":""},{"path":"/reference/compare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare clustering methods — cmp_make_clusters","text":"","code":"# \\donttest{ mat = readRDS(system.file(\"extdata\", \"random_GO_BP_sim_mat.rds\",     package = \"simplifyEnrichment\")) compare_clustering_methods(mat) #> Cluster 500 terms by 'kmeans'... #>  16 clusters, used 3.504993 secs. #> Cluster 500 terms by 'pam'... #>  5 clusters, used 21.06912 secs. #> Cluster 500 terms by 'dynamicTreeCut'... #>  60 clusters, used 0.577157 secs. #> Cluster 500 terms by 'apcluster'... #>  41 clusters, used 0.6789331 secs. #> Cluster 500 terms by 'hdbscan'... #>  14 clusters, used 0.172466 secs. #> Cluster 500 terms by 'fast_greedy'... #>  6 clusters, used 0.104732 secs. #> Cluster 500 terms by 'louvain'... #>  6 clusters, used 0.08450413 secs. #> Cluster 500 terms by 'walktrap'... #>  6 clusters, used 0.263876 secs. #> Cluster 500 terms by 'MCL'... #>  6 clusters, used 1.821683 secs. #> Cluster 500 terms by 'binary_cut'... #>  19 clusters, used 4.193117 secs.  compare_clustering_methods(mat, plot_type = \"heatmap\") #> Cluster 500 terms by 'kmeans'... #>  19 clusters, used 3.305151 secs. #> Cluster 500 terms by 'pam'... #>  5 clusters, used 21.00071 secs. #> Cluster 500 terms by 'dynamicTreeCut'... #>  60 clusters, used 0.1564171 secs. #> Cluster 500 terms by 'apcluster'... #>  41 clusters, used 0.7714469 secs. #> Cluster 500 terms by 'hdbscan'... #>  14 clusters, used 0.1589549 secs. #> Cluster 500 terms by 'fast_greedy'... #>  6 clusters, used 0.09291291 secs. #> Cluster 500 terms by 'louvain'... #>  6 clusters, used 0.07026696 secs. #> Cluster 500 terms by 'walktrap'... #>  6 clusters, used 0.2535839 secs. #> Cluster 500 terms by 'MCL'... #>  6 clusters, used 1.781449 secs. #> Cluster 500 terms by 'binary_cut'... #>  18 clusters, used 4.113788 secs.  # }"},{"path":"/reference/compare_clustering_methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare clustering methods — compare_clustering_methods","title":"Compare clustering methods — compare_clustering_methods","text":"Compare clustering methods","code":""},{"path":"/reference/compare_clustering_methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare clustering methods — compare_clustering_methods","text":"","code":"compare_clustering_methods(   mat,   method = setdiff(all_clustering_methods(), \"mclust\"),   plot_type = c(\"mixed\", \"heatmap\"),   nrow = 3,   verbose = TRUE )"},{"path":"/reference/compare_clustering_methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare clustering methods — compare_clustering_methods","text":"mat similarity matrix. method methods compare. available methods all_clustering_methods. value takes available methods. default mclust excluded long runtime. plot_type See explanation cmp_make_plot. nrow Number rows layout plot_type set heatmap. verbose Whether print messages.","code":""},{"path":"/reference/compare_clustering_methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare clustering methods — compare_clustering_methods","text":"value returned.","code":""},{"path":"/reference/compare_clustering_methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare clustering methods — compare_clustering_methods","text":"function compares following clustering methods default: -kmeans see cluster_by_kmeans. -pam see cluster_by_pam. -dynamicTreeCut see cluster_by_dynamicTreeCut. -mclust see cluster_by_mclust. default included. -apcluster see cluster_by_apcluster. -hdbscan see cluster_by_hdbscan. -fast_greedy see cluster_by_fast_greedy. -louvain see cluster_by_louvain. -walktrap see cluster_by_walktrap. -MCL see cluster_by_MCL. -binary_cut see binary_cut. functon basically wrapper function. calls following two functions: cmp_make_clusters: applies clustering different methods. cmp_make_plot: makes plots.","code":""},{"path":"/reference/compare_clustering_methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare clustering methods — compare_clustering_methods","text":"","code":"# \\donttest{ mat = readRDS(system.file(\"extdata\", \"random_GO_BP_sim_mat.rds\",     package = \"simplifyEnrichment\")) compare_clustering_methods(mat) #> Cluster 500 terms by 'kmeans'... #>  18 clusters, used 3.221053 secs. #> Cluster 500 terms by 'pam'... #>  5 clusters, used 20.67218 secs. #> Cluster 500 terms by 'dynamicTreeCut'... #>  60 clusters, used 0.132031 secs. #> Cluster 500 terms by 'apcluster'... #>  41 clusters, used 0.7050171 secs. #> Cluster 500 terms by 'hdbscan'... #>  14 clusters, used 0.163321 secs. #> Cluster 500 terms by 'fast_greedy'... #>  6 clusters, used 0.06812 secs. #> Cluster 500 terms by 'louvain'... #>  6 clusters, used 0.07268381 secs. #> Cluster 500 terms by 'walktrap'... #>  6 clusters, used 0.780349 secs. #> Cluster 500 terms by 'MCL'... #>  6 clusters, used 1.736204 secs. #> Cluster 500 terms by 'binary_cut'... #>  19 clusters, used 4.215953 secs.  compare_clustering_methods(mat, plot_type = \"heatmap\") #> Cluster 500 terms by 'kmeans'... #>  23 clusters, used 3.011423 secs. #> Cluster 500 terms by 'pam'... #>  5 clusters, used 20.29424 secs. #> Cluster 500 terms by 'dynamicTreeCut'... #>  60 clusters, used 0.13887 secs. #> Cluster 500 terms by 'apcluster'... #>  41 clusters, used 0.7265048 secs. #> Cluster 500 terms by 'hdbscan'... #>  14 clusters, used 0.1619201 secs. #> Cluster 500 terms by 'fast_greedy'... #>  6 clusters, used 0.061584 secs. #> Cluster 500 terms by 'louvain'... #>  6 clusters, used 0.0815661 secs. #> Cluster 500 terms by 'walktrap'... #>  6 clusters, used 0.2488348 secs. #> Cluster 500 terms by 'MCL'... #>  6 clusters, used 1.787284 secs. #> Cluster 500 terms by 'binary_cut'... #>  19 clusters, used 5.14202 secs.  # }"},{"path":"/reference/count_words.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate word frequency — count_words","title":"Calculate word frequency — count_words","text":"Calculate word frequency","code":""},{"path":"/reference/count_words.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate word frequency — count_words","text":"","code":"count_words(   term,   exclude_words = NULL,   stop_words = stopwords(),   min_word_length = 1,   tokenizer = \"words\",   transform_case = tolower,   remove_numbers = TRUE,   remove_punctuation = TRUE,   custom_transformer = NULL,   stemming = FALSE,   dictionary = NULL )"},{"path":"/reference/count_words.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate word frequency — count_words","text":"term vector description texts. exclude_words words excluded. stop_words stop words removed. min_word_length Minimum length word counted. tokenizer tokenizer function, one values accepted tm::termFreq. transform_case function normalizing lettercase words. remove_numbers Whether remove numbers. remove_punctuation Whether remove punctuation. custom_transformer Custom function transforms words. stemming Whether keep roots inflected words. dictionary vector words counted (given words excluded).","code":""},{"path":"/reference/count_words.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate word frequency — count_words","text":"data frame words frequencies.","code":""},{"path":"/reference/count_words.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate word frequency — count_words","text":"text preprocessing followings instruction http://www.sthda.com/english/wiki/word-cloud-generator--r-one-killer-function---everything--need.","code":""},{"path":"/reference/count_words.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate word frequency — count_words","text":"","code":"gm = readRDS(system.file(\"extdata\", \"random_GO_BP_sim_mat.rds\", package = \"simplifyEnrichment\")) go_id = rownames(gm) go_term = AnnotationDbi::select(GO.db::GO.db, keys = go_id, columns = \"TERM\")$TERM #> 'select()' returned 1:1 mapping between keys and columns count_words(go_term) |> head() #>                  word freq #> regulation regulation  179 #> process       process   63 #> positive     positive   61 #> cell             cell   59 #> negative     negative   57 #> signaling   signaling   43"},{"path":"/reference/dend.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply functions on every node in a dendrogram — dend_node_apply","title":"Apply functions on every node in a dendrogram — dend_node_apply","text":"Apply functions every node dendrogram","code":""},{"path":"/reference/dend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply functions on every node in a dendrogram — dend_node_apply","text":"","code":"dend_node_apply(dend, fun)  edit_node(dend, fun = function(d, index) d)"},{"path":"/reference/dend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply functions on every node in a dendrogram — dend_node_apply","text":"dend dendrogram object. fun self-defined function.","code":""},{"path":"/reference/dend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply functions on every node in a dendrogram — dend_node_apply","text":"dend_node_apply() returns vector list, depends whether fun returns scalar complex values. edit_node() returns dendrogram object.","code":""},{"path":"/reference/dend.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply functions on every node in a dendrogram — dend_node_apply","text":"dend_node_apply() returns vector list length number nodes dendrogram. self-defined function can one single argument sub-dendrogram certain node. E.g. get number members every node:   self-defined function can second argument, index current sub-dendrogram complete dendrogram. E.g. dend[[1]] first child node complete dendrogram dend[[c(1, 2)]] second child node dend[[1]], et al. makes certain node, possible get information child nodes parent nodes.   Note top node, value index NULL. edit_node(), fun one argument, basically stats::dendrapply(), can second argument index node dendrogram, makes possible get information child nodes parent nodes specific node. example, first assign random values every node dendrogram:   every node, take maximal absolute difference child nodes parent node attribute abs_diff.","code":"dend_node_apply(dend, function(d) attr(d, \"members\")) dend_node_apply(dend, function(d, index) {     dend[[c(index, 1)]] # is the first child node of d, or simply d[[1]]     dend[[index[-length(index)]]] # is the parent node of d     ... }) mat = matrix(rnorm(100), 10) dend = as.dendrogram(hclust(dist(mat))) dend = edit_node(dend, function(d) {attr(d, 'score') = runif(1); d}) dend = edit_node(dend, function(d, index) {     n = length(index)     s = attr(d, \"score\")     if(is.null(index)) {  # d is the top node         s_children = sapply(d, function(x) attr(x, \"score\"))         s_parent = NULL     } else if(is.leaf(d)) { # d is the leaf         s_children = NULL         s_parent = attr(dend[[index[-n]]], \"score\")     } else {         s_children = sapply(d, function(x) attr(x, \"score\"))         s_parent = attr(dend[[index[-n]]], \"score\")     }     abs_diff = max(abs(s - c(s_children, s_parent)))     attr(d, \"abs_diff\") = abs_diff     return(d) })"},{"path":"/reference/dend.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply functions on every node in a dendrogram — dend_node_apply","text":"","code":"mat = matrix(rnorm(100), 10) dend = as.dendrogram(hclust(dist(mat))) # number of members on every node dend_node_apply(dend, function(d) attr(d, \"members\")) #>  [1] 10  2  1  1  8  1  7  2  1  1  5  2  1  1  3  1  2  1  1 # the depth on every node dend_node_apply(dend, function(d, index) length(index)) #>  [1] 0 1 2 2 1 2 2 3 4 4 3 4 5 5 4 5 5 6 6"},{"path":"/reference/difference_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Difference score — difference_score","title":"Difference score — difference_score","text":"Difference score","code":""},{"path":"/reference/difference_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Difference score — difference_score","text":"","code":"difference_score(mat, cl)"},{"path":"/reference/difference_score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Difference score — difference_score","text":"mat similarity matrix. cl Cluster labels.","code":""},{"path":"/reference/difference_score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Difference score — difference_score","text":"numeric scalar.","code":""},{"path":"/reference/difference_score.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Difference score — difference_score","text":"function measures different similarity values terms belong clusters different clusters. difference score Kolmogorov-Smirnov statistic two distributions.","code":""},{"path":"/reference/difference_score.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Difference score — difference_score","text":"","code":"mat = readRDS(system.file(\"extdata\", \"random_GO_BP_sim_mat.rds\",      package = \"simplifyEnrichment\")) cl = binary_cut(mat) difference_score(mat, cl) #> [1] 0.8330003"},{"path":"/reference/export_to_shiny_app.html","id":null,"dir":"Reference","previous_headings":"","what":"Interactively visualize the similarity heatmap — export_to_shiny_app","title":"Interactively visualize the similarity heatmap — export_to_shiny_app","text":"Interactively visualize similarity heatmap","code":""},{"path":"/reference/export_to_shiny_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interactively visualize the similarity heatmap — export_to_shiny_app","text":"","code":"export_to_shiny_app(mat, cl = binary_cut(mat))"},{"path":"/reference/export_to_shiny_app.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interactively visualize the similarity heatmap — export_to_shiny_app","text":"mat similarity matrix. cl Cluster labels inferred similarity matrix, e.g. cluster_terms() binary_cut().","code":""},{"path":"/reference/export_to_shiny_app.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interactively visualize the similarity heatmap — export_to_shiny_app","text":"shiny application.","code":""},{"path":"/reference/export_to_shiny_app.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interactively visualize the similarity heatmap — export_to_shiny_app","text":"","code":"if(interactive()) {     mat = readRDS(system.file(\"extdata\", \"random_GO_BP_sim_mat.rds\",          package = \"simplifyEnrichment\"))     cl = binary_cut(mat)     export_to_shiny_app(mat, cl) }"},{"path":"/reference/guess_ont.html","id":null,"dir":"Reference","previous_headings":"","what":"Guess the ontology of the input GO IDs — guess_ont","title":"Guess the ontology of the input GO IDs — guess_ont","text":"Guess ontology input GO IDs","code":""},{"path":"/reference/guess_ont.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Guess the ontology of the input GO IDs — guess_ont","text":"","code":"guess_ont(go_id, db = \"org.Hs.eg.db\")"},{"path":"/reference/guess_ont.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Guess the ontology of the input GO IDs — guess_ont","text":"go_id vector GO IDs. db Annotation database. https://bioconductor.org/packages/3.10/BiocViews.html#___OrgDb. value can also directly OrgDb object.","code":""},{"path":"/reference/guess_ont.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Guess the ontology of the input GO IDs — guess_ont","text":"single character scalar \"BP\", \"CC\" \"MF\". one ontologies detected. returns NULL.","code":""},{"path":"/reference/guess_ont.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Guess the ontology of the input GO IDs — guess_ont","text":"10 GO IDs randomly sampled checked.","code":""},{"path":"/reference/guess_ont.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Guess the ontology of the input GO IDs — guess_ont","text":"","code":"# \\donttest{ go_id = random_GO(100) guess_ont(go_id) #> [1] \"BP\" # }"},{"path":"/reference/ht_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize the similarity matrix and the clustering — ht_clusters","title":"Visualize the similarity matrix and the clustering — ht_clusters","text":"Visualize similarity matrix clustering","code":""},{"path":"/reference/ht_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize the similarity matrix and the clustering — ht_clusters","text":"","code":"ht_clusters(   mat,   cl,   dend = NULL,   col = c(\"white\", \"red\"),   draw_word_cloud = TRUE,   min_term = round(nrow(mat) * 0.01),   order_by_size = FALSE,   stat = \"pvalue\",   min_stat = ifelse(stat == \"count\", 5, 0.05),   exclude_words = character(0),   max_words = 10,   word_cloud_grob_param = list(),   fontsize_range = c(4, 16),   bg_gp = gpar(fill = \"#DDDDDD\", col = \"#AAAAAA\"),   column_title = NULL,   ht_list = NULL,   use_raster = TRUE,   run_draw = TRUE,   ... )"},{"path":"/reference/ht_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize the similarity matrix and the clustering — ht_clusters","text":"mat similarity matrix. cl Cluster labels inferred similarity matrix, e.g. cluster_terms() binary_cut(). dend Used internally. col vector colors map 0 97.5^th percentile similarity values. value can also color mapping function generated circlize::colorRamp2(). draw_word_cloud Whether draw word clouds. min_term Minimal number functional terms cluster. clusters size less min_term merged one separated cluster heatmap. order_by_size Whether reorder clusters sizes. cluster merged small clusters (size < min_term) always put bottom heatmap. stat Type value mapping font size keywords word clouds. two options: \"count\": simply number keywords; \"pvalue\": enrichment keywords performed (fisher's exact test) -log10(pvalue) used map font sizes. min_stat Minimal value stat selecting keywords. exclude_words Words excluded word cloud. max_words Maximal number words visualized word cloud. word_cloud_grob_param list graphic parameters passed word_cloud_grob(). fontsize_range range font size. value numeric vector length two. font size interpolation linear. bg_gp Graphics parameters controlling word cloud annotation background. column_title Column title heatmap. ht_list list additional heatmaps added left similarity heatmap. use_raster Whether write heatmap raster image. run_draw Internally used. ... arguments passed ComplexHeatmap::draw,HeatmapList-method.","code":""},{"path":"/reference/ht_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize the similarity matrix and the clustering — ht_clusters","text":"ComplexHeatmap::HeatmapList object.","code":""},{"path":"/reference/ht_clusters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize the similarity matrix and the clustering — ht_clusters","text":"","code":"# \\donttest{ mat = readRDS(system.file(\"extdata\", \"random_GO_BP_sim_mat.rds\",     package = \"simplifyEnrichment\")) cl = binary_cut(mat) ht_clusters(mat, cl, word_cloud_grob_param = list(max_width = 80)) #> Perform keywords enrichment for 11 GO lists...  ht_clusters(mat, cl, word_cloud_grob_param = list(max_width = 80),     order_by_size = TRUE) #> Perform keywords enrichment for 11 GO lists...  # }"},{"path":"/reference/keyword_enrichment_from_GO.html","id":null,"dir":"Reference","previous_headings":"","what":"Keyword enrichment for GO terms — keyword_enrichment_from_GO","title":"Keyword enrichment for GO terms — keyword_enrichment_from_GO","text":"Keyword enrichment GO terms","code":""},{"path":"/reference/keyword_enrichment_from_GO.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Keyword enrichment for GO terms — keyword_enrichment_from_GO","text":"","code":"keyword_enrichment_from_GO(go_id, min_bg = 5, min_term = 2)"},{"path":"/reference/keyword_enrichment_from_GO.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Keyword enrichment for GO terms — keyword_enrichment_from_GO","text":"go_id vector GO IDs. min_bg Minimal number GO terms (background, .e. GO temrs GO database) contain specific keyword. min_term Minimal number GO terms (GO terms go_id) contain specific keyword.","code":""},{"path":"/reference/keyword_enrichment_from_GO.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Keyword enrichment for GO terms — keyword_enrichment_from_GO","text":"data frame keyword enrichment results.","code":""},{"path":"/reference/keyword_enrichment_from_GO.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Keyword enrichment for GO terms — keyword_enrichment_from_GO","text":"enrichment applied Fisher's exact test. keyword, following 2x2 contigency table:   s11, s12, s21 s22 counts GO terms four categories.","code":"| contains the keyword | does not contain the keyword     In the GO set     |          s11         |          s12     Not in the GO set |          s21         |          s22"},{"path":"/reference/keyword_enrichment_from_GO.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Keyword enrichment for GO terms — keyword_enrichment_from_GO","text":"","code":"# \\donttest{ go_id = random_GO(100) keyword_enrichment_from_GO(go_id) #>             keyword n_term  n_bg            p        padj #> 1             built      2     5 0.0000507144 0.003245722 #> 2           domains      2     5 0.0000507144 0.003245722 #> 3             based      2     8 0.0001413703 0.008764960 #> 4       superfamily      2    14 0.0004553889 0.027778722 #> 5        regulation     39 10445 0.0004587624 0.027778722 #> 6        osteoclast      2    15 0.0005246716 0.030955622 #> 7       respiration      2    16 0.0005987379 0.034726799 #> 8              glia      2    17 0.0006775663 0.038621281 #> 9         receptors      2    18 0.0007611353 0.042623576 #> 10           guided      2    19 0.0008494233 0.046718279 #> 11         adaptive      2    24 0.0013609020 0.073488709 #> 12        migration      5   389 0.0019775906 0.104812301 #> 13 calciumdependent      2    29 0.0019871758 0.104812301 #> 14        adenosine      2    37 0.0032215001 0.164296505 #> 15         cerebral      2    39 0.0035737292 0.178686462 #> 16           radial      2    39 0.0035737292 0.178686462 #> 17    monophosphate      2    42 0.0041341544 0.198439411 #> 18          cardiac      4   295 0.0046578742 0.218920087 #> 19         motility      2    52 0.0062738567 0.288597407 #> 20          somatic      2    60 0.0082767213 0.372452460 #> 21   immunoglobulin      2    66 0.0099423153 0.437461872 #> 22     inflammatory      2    83 0.0153853354 0.661569424 #> 23           cortex      2    86 0.0164523217 0.690997512 #> 24 neurotransmitter      2    88 0.0171807518 0.704410824 #> 25       nucleoside      2    90 0.0179227079 0.716908317 #> 26    recombination      2    90 0.0179227079 0.716908317 #> 27           tissue      2   121 0.0310544603 1.000000000 #> 28         negative     13  3274 0.0338722862 1.000000000 #> 29        metabolic      8  1787 0.0504289202 1.000000000 #> 30         involved      8  1850 0.0593864344 1.000000000 #> 31            blood      2   177 0.0614455024 1.000000000 #> 32        detection      2   182 0.0645108931 1.000000000 #> 33         positive     12  3338 0.0751441243 1.000000000 #> 34    establishment      2   209 0.0819010201 1.000000000 #> 35       production      3   467 0.0903408024 1.000000000 #> 36           immune      2   238 0.1019652751 1.000000000 #> 37         response      8  2112 0.1069953416 1.000000000 #> 38    morphogenesis      4   798 0.1083531078 1.000000000 #> 39       activation      2   298 0.1469853367 1.000000000 #> 40         stimulus      2   314 0.1595983149 1.000000000 #> 41         cellular      4   932 0.1620160107 1.000000000 #> 42          protein      6  1623 0.1635079279 1.000000000 #> 43          process     17  5825 0.1646747271 1.000000000 #> 44    mitochondrial      2   321 0.1651789873 1.000000000 #> 45           muscle      3   623 0.1685057945 1.000000000 #> 46          pathway      5  1287 0.1685219263 1.000000000 #> 47        transport      5  1291 0.1700121702 1.000000000 #> 48          vesicle      2   359 0.1960133950 1.000000000 #> 49        apoptotic      2   375 0.2092105723 1.000000000 #> 50        signaling      5  1429 0.2243614616 1.000000000 #> 51    proliferation      2   454 0.2752746754 1.000000000 #> 52    transmembrane      3   868 0.3148038518 1.000000000 #> 53           kinase      2   504 0.3171227576 1.000000000 #> 54     localization      2   517 0.3279304662 1.000000000 #> 55              ion      2   526 0.3353872079 1.000000000 #> 56           factor      2   554 0.3584269711 1.000000000 #> 57      development      4  1455 0.4209315010 1.000000000 #> 58              dna      2   687 0.4631534118 1.000000000 #> 59             cell      9  3738 0.4769800615 1.000000000 #> 60        catabolic      3  1547 0.6861147181 1.000000000 #> 61         receptor      3  1561 0.6920083901 1.000000000 #> 62         membrane      2  1219 0.7675549006 1.000000000 #> 63     biosynthetic      3  2035 0.8458255727 1.000000000 #> 64         activity      4 10285 0.9999999857 1.000000000 # }"},{"path":"/reference/node_partition.html","id":null,"dir":"Reference","previous_headings":"","what":"Partition the matrix — partition_by_kmeans","title":"Partition the matrix — partition_by_kmeans","text":"Partition matrix","code":""},{"path":"/reference/node_partition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partition the matrix — partition_by_kmeans","text":"","code":"partition_by_kmeans(mat, n_repeats = 10)  partition_by_pam(mat)  partition_by_hclust(mat)  partition_by_kmeanspp(mat)"},{"path":"/reference/node_partition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partition the matrix — partition_by_kmeans","text":"mat submatrix binary cut clustering process. n_repeats Number repeated runs k-means clustering.","code":""},{"path":"/reference/node_partition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partition the matrix — partition_by_kmeans","text":"partitioning functions split matrix two groups return categorical vector labels 1 2.","code":""},{"path":"/reference/node_partition.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partition the matrix — partition_by_kmeans","text":"functions can set partition_fun argument binary_cut(). partition_by_kmeans(): Since k-means clustering brings randomness, function performs k-means clustering several times (controlled n_repeats) uses final consensus partitioning results. partition_by_pam(): clustering performed cluster::pam() pamonce argument set 5. partition_by_hclust(): \"ward.D2\" clusering method used. partition_by_kmeanspp(): uses kmeanspp method flexclust package.","code":""},{"path":"/reference/random_GO.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate random GO IDs — random_GO","title":"Generate random GO IDs — random_GO","text":"Generate random GO IDs","code":""},{"path":"/reference/random_GO.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate random GO IDs — random_GO","text":"","code":"random_GO(n, ont = c(\"BP\", \"CC\", \"MF\"), db = \"org.Hs.eg.db\")"},{"path":"/reference/random_GO.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate random GO IDs — random_GO","text":"n Number GO IDs. ont GO ontology. Value one \"BP\", \"CC\" \"MF\". db Annotation database. https://bioconductor.org/packages/3.10/BiocViews.html#___OrgDb.","code":""},{"path":"/reference/random_GO.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate random GO IDs — random_GO","text":"vector GO IDs.","code":""},{"path":"/reference/random_GO.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate random GO IDs — random_GO","text":"","code":"# \\donttest{ random_GO(100) #>   [1] \"GO:1901394\" \"GO:0018282\" \"GO:0070676\" \"GO:0021702\" \"GO:1905397\" #>   [6] \"GO:0060061\" \"GO:0099068\" \"GO:0072289\" \"GO:0018211\" \"GO:0050765\" #>  [11] \"GO:0042758\" \"GO:2001236\" \"GO:1990927\" \"GO:1903609\" \"GO:0051541\" #>  [16] \"GO:0043416\" \"GO:0062234\" \"GO:0050999\" \"GO:0014870\" \"GO:2000107\" #>  [21] \"GO:0044782\" \"GO:1990953\" \"GO:0061567\" \"GO:0045794\" \"GO:1905051\" #>  [26] \"GO:0038171\" \"GO:0009165\" \"GO:1904542\" \"GO:1902573\" \"GO:1901301\" #>  [31] \"GO:0032201\" \"GO:1905221\" \"GO:0048736\" \"GO:0021891\" \"GO:0021998\" #>  [36] \"GO:0031102\" \"GO:0060462\" \"GO:0043149\" \"GO:0002419\" \"GO:0045136\" #>  [41] \"GO:0099170\" \"GO:0016024\" \"GO:0010816\" \"GO:1901964\" \"GO:0072070\" #>  [46] \"GO:0006555\" \"GO:1903351\" \"GO:0060516\" \"GO:1990172\" \"GO:0034370\" #>  [51] \"GO:1904381\" \"GO:0098884\" \"GO:2001046\" \"GO:0050691\" \"GO:1904684\" #>  [56] \"GO:0002431\" \"GO:0033693\" \"GO:0046888\" \"GO:0003171\" \"GO:0022412\" #>  [61] \"GO:0006684\" \"GO:1903348\" \"GO:0060957\" \"GO:0042635\" \"GO:0009948\" #>  [66] \"GO:0034111\" \"GO:0070918\" \"GO:0045647\" \"GO:0051639\" \"GO:1905806\" #>  [71] \"GO:0000054\" \"GO:0060828\" \"GO:0044241\" \"GO:1900029\" \"GO:0051712\" #>  [76] \"GO:0043380\" \"GO:0051124\" \"GO:0044663\" \"GO:0032834\" \"GO:0097213\" #>  [81] \"GO:0010920\" \"GO:0072702\" \"GO:0046512\" \"GO:0001886\" \"GO:0018026\" #>  [86] \"GO:1904850\" \"GO:0034219\" \"GO:0045292\" \"GO:0046825\" \"GO:0042573\" #>  [91] \"GO:0061086\" \"GO:0036151\" \"GO:0021707\" \"GO:0045109\" \"GO:0035570\" #>  [96] \"GO:0002504\" \"GO:0018105\" \"GO:1904651\" \"GO:0032497\" \"GO:0071941\" # }"},{"path":"/reference/scale_fontsize.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale font size — scale_fontsize","title":"Scale font size — scale_fontsize","text":"Scale font size","code":""},{"path":"/reference/scale_fontsize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale font size — scale_fontsize","text":"","code":"scale_fontsize(x, rg = c(1, 30), fs = c(4, 16))"},{"path":"/reference/scale_fontsize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale font size — scale_fontsize","text":"x numeric vector. rg range. fs Range font size.","code":""},{"path":"/reference/scale_fontsize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale font size — scale_fontsize","text":"numeric vector.","code":""},{"path":"/reference/scale_fontsize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Scale font size — scale_fontsize","text":"linear interpolation.","code":""},{"path":"/reference/scale_fontsize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scale font size — scale_fontsize","text":"","code":"x = runif(10, min = 1, max = 20) # scale x to fontsize 4 to 16. scale_fontsize(x) #>  [1]  7  8  7  4  5  7  6 11  5 10"},{"path":"/reference/se_opt.html","id":null,"dir":"Reference","previous_headings":"","what":"Global parameters — se_opt","title":"Global parameters — se_opt","text":"Global parameters","code":""},{"path":"/reference/se_opt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global parameters — se_opt","text":"","code":"se_opt(..., RESET = FALSE, READ.ONLY = NULL, LOCAL = FALSE, ADD = FALSE)"},{"path":"/reference/se_opt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global parameters — se_opt","text":"... Arguments parameters, see \"details\" section. RESET Whether reset default values. READ.Please ignore. LOCAL Please ignore. ADD Please ignore.","code":""},{"path":"/reference/se_opt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Global parameters — se_opt","text":"GlobalOptionsFun object.","code":""},{"path":"/reference/se_opt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Global parameters — se_opt","text":"following global options: verobse: Whether print messages.","code":""},{"path":"/reference/select_cutoff.html","id":null,"dir":"Reference","previous_headings":"","what":"Select the cutoff for binary cut — select_cutoff","title":"Select the cutoff for binary cut — select_cutoff","text":"Select cutoff binary cut","code":""},{"path":"/reference/select_cutoff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select the cutoff for binary cut — select_cutoff","text":"","code":"select_cutoff(   mat,   cutoff = seq(0.6, 0.98, by = 0.01),   verbose = se_opt$verbose,   ... )"},{"path":"/reference/select_cutoff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select the cutoff for binary cut — select_cutoff","text":"mat similarity matrix. cutoff list cutoffs test. Note range cutoff values inside [0.5, 1]. verbose Whether print messages. ... Pass binary_cut().","code":""},{"path":"/reference/select_cutoff.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Select the cutoff for binary cut — select_cutoff","text":"Binary cut applied cutoff clustering results evaluated following metrics: difference score, calculated difference_score(). number clusters. block mean, mean similarity blocks diagonal heatmap.","code":""},{"path":"/reference/select_cutoff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select the cutoff for binary cut — select_cutoff","text":"","code":"# \\donttest{ mat = readRDS(system.file(\"extdata\", \"random_GO_BP_sim_mat.rds\",     package = \"simplifyEnrichment\")) select_cutoff(mat) #> 1/39, cutoff = 0.6... #> 2/39, cutoff = 0.61... #> 3/39, cutoff = 0.62... #> 4/39, cutoff = 0.63... #> 5/39, cutoff = 0.64... #> 6/39, cutoff = 0.65... #> 7/39, cutoff = 0.66... #> 8/39, cutoff = 0.67... #> 9/39, cutoff = 0.68... #> 10/39, cutoff = 0.69... #> 11/39, cutoff = 0.7... #> 12/39, cutoff = 0.71... #> 13/39, cutoff = 0.72... #> 14/39, cutoff = 0.73... #> 15/39, cutoff = 0.74... #> 16/39, cutoff = 0.75... #> 17/39, cutoff = 0.76... #> 18/39, cutoff = 0.77... #> 19/39, cutoff = 0.78... #> 20/39, cutoff = 0.79... #> 21/39, cutoff = 0.8... #> 22/39, cutoff = 0.81... #> 23/39, cutoff = 0.82... #> 24/39, cutoff = 0.83... #> 25/39, cutoff = 0.84... #> 26/39, cutoff = 0.85... #> 27/39, cutoff = 0.86... #> 28/39, cutoff = 0.87... #> 29/39, cutoff = 0.88... #> 30/39, cutoff = 0.89... #> 31/39, cutoff = 0.9... #> 32/39, cutoff = 0.91... #> 33/39, cutoff = 0.92... #> 34/39, cutoff = 0.93... #> 35/39, cutoff = 0.94... #> 36/39, cutoff = 0.95... #> 37/39, cutoff = 0.96... #> 38/39, cutoff = 0.97... #> 39/39, cutoff = 0.98...  # }"},{"path":"/reference/simplifyEnrichment.html","id":null,"dir":"Reference","previous_headings":"","what":"Simplify functional enrichment results — simplifyEnrichment","title":"Simplify functional enrichment results — simplifyEnrichment","text":"Simplify functional enrichment results","code":""},{"path":"/reference/simplifyEnrichment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simplify functional enrichment results — simplifyEnrichment","text":"","code":"simplifyEnrichment(   mat,   method = \"binary_cut\",   control = list(),   plot = TRUE,   verbose = TRUE,   column_title = qq(\"@{nrow(mat)} terms clustered by '@{method}'\"),   ht_list = NULL,   ... )"},{"path":"/reference/simplifyEnrichment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simplify functional enrichment results — simplifyEnrichment","text":"mat similarity matrix. method Method clustering matrix. See cluster_terms. control list parameters controlling clustering method, passed cluster_terms. plot Whether make heatmap. verbose Whether print messages. column_title Column title heatmap. ht_list list additional heatmaps added left similarity heatmap. ... Arguments passed ht_clusters.","code":""},{"path":"/reference/simplifyEnrichment.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simplify functional enrichment results — simplifyEnrichment","text":"usage simplifyGO.","code":""},{"path":"/reference/simplifyGO.html","id":null,"dir":"Reference","previous_headings":"","what":"Simplify Gene Ontology (GO) enrichment results — simplifyGO","title":"Simplify Gene Ontology (GO) enrichment results — simplifyGO","text":"Simplify Gene Ontology (GO) enrichment results","code":""},{"path":"/reference/simplifyGO.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simplify Gene Ontology (GO) enrichment results — simplifyGO","text":"","code":"simplifyGO(   mat,   method = \"binary_cut\",   control = list(),   plot = TRUE,   verbose = TRUE,   column_title = qq(\"@{nrow(mat)} GO terms clustered by '@{method}'\"),   ht_list = NULL,   ... )  simplifyEnrichment(...)"},{"path":"/reference/simplifyGO.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simplify Gene Ontology (GO) enrichment results — simplifyGO","text":"mat GO similarity matrix. can also provide vector GO IDs argument. method Method clustering matrix. See cluster_terms(). control list parameters controlling clustering method, passed cluster_terms(). plot Whether make heatmap. verbose Whether print messages. column_title Column title heatmap. ht_list list additional heatmaps added left similarity heatmap. ... Arguments passed ht_clusters().","code":""},{"path":"/reference/simplifyGO.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simplify Gene Ontology (GO) enrichment results — simplifyGO","text":"data frame two columns: GO IDs cluster labels.","code":""},{"path":"/reference/simplifyGO.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simplify Gene Ontology (GO) enrichment results — simplifyGO","text":"basically wrapper function first runs cluster_terms() cluster GO terms runs ht_clusters() visualize clustering. arguments simplifyGO() passed ht_clusters() : draw_word_cloud: Whether draw word clouds. min_term: Minimal number GO terms cluster. clusters size less min_term merged one single cluster heatmap. order_by_size: Whether reorder GO clusters sizes. cluster merged small clusters (size < min_term) always put bottom heatmap. stat: values keywords used map font sizes word clouds. exclude_words: Words excluded word cloud. max_words: Maximal number words visualized word cloud. word_cloud_grob_param: list graphic parameters passed word_cloud_grob(). fontsize_range range font size. value numeric vector length two. minimal font size mapped word frequency value 1 maximal font size mapped maximal word frequency. font size interlopation linear. bg_gp: Graphic parameters controlling background word cloud annotations.","code":""},{"path":"/reference/simplifyGO.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simplify Gene Ontology (GO) enrichment results — simplifyGO","text":"","code":"# \\donttest{ set.seed(123) go_id = random_GO(500) mat = GO_similarity(go_id) #> You haven't provided value for `ont`, guess it as `BP`. #> term_sim_method: Sim_XGraSM_2013 #> IC_method: IC_annotation df = simplifyGO(mat, word_cloud_grob_param = list(max_width = 80)) #> Cluster 500 terms by 'binary_cut'... #>  15 clusters, used 4.969077 secs. #> Perform keywords enrichment for 8 GO lists...  head(df) #>           id cluster #> 1 GO:0009237       1 #> 2 GO:0009416       2 #> 3 GO:0070723       2 #> 4 GO:0051316       3 #> 5 GO:0140495       4 #> 6 GO:0010902       3 # }"},{"path":"/reference/simplifyGOFromMultipleLists.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform simplifyGO analysis with multiple lists of GO IDs — simplifyGOFromMultipleLists","title":"Perform simplifyGO analysis with multiple lists of GO IDs — simplifyGOFromMultipleLists","text":"Perform simplifyGO analysis multiple lists GO IDs","code":""},{"path":"/reference/simplifyGOFromMultipleLists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform simplifyGO analysis with multiple lists of GO IDs — simplifyGOFromMultipleLists","text":"","code":"simplifyGOFromMultipleLists(   lt,   go_id_column = NULL,   padj_column = NULL,   padj_cutoff = 0.01,   filter = function(x) any(x < padj_cutoff),   default = 1,   ont = NULL,   db = \"org.Hs.eg.db\",   measure = \"Sim_XGraSM_2013\",   heatmap_param = list(NULL),   show_barplot = TRUE,   method = \"binary_cut\",   control = list(),   min_term = NULL,   verbose = TRUE,   column_title = NULL,   ... )"},{"path":"/reference/simplifyGOFromMultipleLists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform simplifyGO analysis with multiple lists of GO IDs — simplifyGOFromMultipleLists","text":"lt data frame, list numeric vectors (e.g. adjusted p-values) numeric vector GO IDs names, list GO IDs. go_id_column Column index GO ID lt contains list data frames. padj_column Column index adjusted p-values lt contains list data frames. padj_cutoff Cut adjusted p-values. filter self-defined function filtering GO IDs. default requires GO IDs significant least one list. default default value adjusted p-values. See Details. ont Pass GO_similarity(). db Pass GO_similarity(). measure Pass GO_similarity(). heatmap_param Parameters controlling heatmap, see Details. show_barplot Whether draw barplots shows numbers significant GO terms clusters. method Pass simplifyGO(). control Pass simplifyGO(). min_term Pass simplifyGO(). verbose Pass simplifyGO(). column_title Pass simplifyGO(). ... Pass simplifyGO().","code":""},{"path":"/reference/simplifyGOFromMultipleLists.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform simplifyGO analysis with multiple lists of GO IDs — simplifyGOFromMultipleLists","text":"input data can three types formats: list numeric vectors adjusted p-values vector GO IDs names. data frame. column GO IDs can specified go_id_column argument column adjusted p-values can specified padj_column argument. columns specified, automatically identified. GO ID column found checking whether column contains GO IDs. adjusted p-value column found comparing column names data frame see whether might column adjusted p-values. two columns used construct numeric vector GO IDs names. list character vectors GO IDs. case, character vector changed numeric vector values take 1 original GO IDs used names vector. Now assume n GO lists, first construct global matrix columns correspond n GO lists rows correspond \"union\" GO IDs lists. value ith GO ID jth list taken corresponding numeric vector lt. jth vector lt contain ith GO ID, value defined default argument taken (e.g. cases numeric values adjusted p-values, default set 1). call matrix M0. Next step filter M0 take subset GO IDs interest. define proper function via argument filter remove GO IDs important analysis. Functions filter applied every row M0 filter function needs return logical value decide whether remove current GO ID. example, values lt adjusted p-values, filter function can set function(x) (x < padj_cutoff) GO ID kept long signfiicant least one list. filter, call filtered matrix M1. GO IDs M1 (row names M1) used clustering. heatmap M1 attached left GO similarity heatmap group-specific (list-specific) patterns can easily observed corresponded GO functions. Argument heatmap_param controls several parameters heatmap M1: transform: self-defined function transform data heatmap visualization. typical case transform adjusted p-values -log10(x). breaks: break values color interpolation. col: corresponding values breaks. labels: corresponding labels. name: Legend title.","code":""},{"path":"/reference/simplifyGOFromMultipleLists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform simplifyGO analysis with multiple lists of GO IDs — simplifyGOFromMultipleLists","text":"","code":"# \\donttest{ # perform functional enrichment on the signatures genes from cola anlaysis  require(cola) #> Loading required package: cola #> ======================================== #> cola version 2.6.0 #> Bioconductor page: http://bioconductor.org/packages/cola/ #> Github page: https://github.com/jokergoo/cola #> Documentation: https://jokergoo.github.io/cola/ #> Examples: https://jokergoo.github.io/cola_collection/ #>  #> If you use it in published research, please cite: #> Gu, Z. cola: an R/Bioconductor package for consensus partitioning  #>   through a general framework. Nucleic Acids Research 2021. #>  #> This message can be suppressed by: #>   suppressPackageStartupMessages(library(cola)) #> ======================================== data(golub_cola)  res = golub_cola[\"ATC:skmeans\"] require(hu6800.db) #> Loading required package: hu6800.db #> Loading required package: AnnotationDbi #> Loading required package: stats4 #> Loading required package: BiocGenerics #>  #> Attaching package: ‘BiocGenerics’ #> The following objects are masked from ‘package:stats’: #>  #>     IQR, mad, sd, var, xtabs #> The following objects are masked from ‘package:base’: #>  #>     Filter, Find, Map, Position, Reduce, anyDuplicated, aperm, append, #>     as.data.frame, basename, cbind, colnames, dirname, do.call, #>     duplicated, eval, evalq, get, grep, grepl, intersect, is.unsorted, #>     lapply, mapply, match, mget, order, paste, pmax, pmax.int, pmin, #>     pmin.int, rank, rbind, rownames, sapply, setdiff, sort, table, #>     tapply, union, unique, unsplit, which.max, which.min #> Loading required package: Biobase #> Welcome to Bioconductor #>  #>     Vignettes contain introductory material; view with #>     'browseVignettes()'. To cite Bioconductor, see #>     'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'. #> Loading required package: IRanges #> Loading required package: S4Vectors #>  #> Attaching package: ‘S4Vectors’ #> The following object is masked from ‘package:utils’: #>  #>     findMatches #> The following objects are masked from ‘package:base’: #>  #>     I, expand.grid, unname #> Loading required package: org.Hs.eg.db #>  x = hu6800ENTREZID mapped_probes = mappedkeys(x) id_mapping = unlist(as.list(x[mapped_probes])) lt = functional_enrichment(res, k = 3, id_mapping = id_mapping) # you can check the value of `lt` #> - 2058/4116 significant genes are taken from 3-group comparisons #> - on k-means group 1/4, 531 genes #> Registered S3 methods overwritten by 'treeio': #>   method              from     #>   MRCA.phylo          tidytree #>   MRCA.treedata       tidytree #>   Nnode.treedata      tidytree #>   Ntip.treedata       tidytree #>   ancestor.phylo      tidytree #>   ancestor.treedata   tidytree #>   child.phylo         tidytree #>   child.treedata      tidytree #>   full_join.phylo     tidytree #>   full_join.treedata  tidytree #>   groupClade.phylo    tidytree #>   groupClade.treedata tidytree #>   groupOTU.phylo      tidytree #>   groupOTU.treedata   tidytree #>   inner_join.phylo    tidytree #>   inner_join.treedata tidytree #>   is.rooted.treedata  tidytree #>   nodeid.phylo        tidytree #>   nodeid.treedata     tidytree #>   nodelab.phylo       tidytree #>   nodelab.treedata    tidytree #>   offspring.phylo     tidytree #>   offspring.treedata  tidytree #>   parent.phylo        tidytree #>   parent.treedata     tidytree #>   root.treedata       tidytree #>   rootnode.phylo      tidytree #>   sibling.phylo       tidytree #>   - 478/531 (90%) genes left after id mapping #>   - gene set enrichment, GO:BP #> - on k-means group 2/4, 811 genes #>   - 640/811 (78.9%) genes left after id mapping #>   - gene set enrichment, GO:BP #> - on k-means group 3/4, 315 genes #>   - 276/315 (87.6%) genes left after id mapping #>   - gene set enrichment, GO:BP #> - on k-means group 4/4, 401 genes #>   - 374/401 (93.3%) genes left after id mapping #>   - gene set enrichment, GO:BP  # a list of data frames simplifyGOFromMultipleLists(lt, padj_cutoff = 0.001) #> Use column 'ID' as `go_id_column`. #> Use column 'p.adjust' as `padj_column`. #> Loading required namespace: gridtext #> 822/6404 GO IDs left for clustering. #> You haven't provided value for `ont`, guess it as `BP`. #> term_sim_method: Sim_XGraSM_2013 #> IC_method: IC_annotation #> Cluster 822 terms by 'binary_cut'... #>  27 clusters, used 8.770008 secs. #> Perform keywords enrichment for 7 GO lists...   # a list of numeric values lt2 = lapply(lt, function(x) structure(x$p.adjust, names = x$ID)) simplifyGOFromMultipleLists(lt2, padj_cutoff = 0.001) #> 822/6404 GO IDs left for clustering. #> You haven't provided value for `ont`, guess it as `BP`. #> term_sim_method: Sim_XGraSM_2013 #> IC_method: IC_annotation #> Cluster 822 terms by 'binary_cut'... #>  31 clusters, used 8.559243 secs. #> Perform keywords enrichment for 8 GO lists...   # a list of GO IDS lt3 = lapply(lt, function(x) x$ID[x$p.adjust < 0.001]) simplifyGOFromMultipleLists(lt3) #> 822/822 GO IDs left for clustering. #> You haven't provided value for `ont`, guess it as `BP`. #> term_sim_method: Sim_XGraSM_2013 #> IC_method: IC_annotation #> Cluster 822 terms by 'binary_cut'... #>  23 clusters, used 9.059406 secs. #> Perform keywords enrichment for 9 GO lists...  # }"},{"path":"/reference/summarizeGO.html","id":null,"dir":"Reference","previous_headings":"","what":"A simplified way to visualize enrichment in GO clusters — summarizeGO","title":"A simplified way to visualize enrichment in GO clusters — summarizeGO","text":"simplified way visualize enrichment GO clusters","code":""},{"path":"/reference/summarizeGO.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A simplified way to visualize enrichment in GO clusters — summarizeGO","text":"","code":"summarizeGO(   go_id,   value = NULL,   aggregate = mean,   method = \"binary_cut\",   control = list(),   verbose = TRUE,   axis_label = \"Value\",   title = \"\",   legend_title = axis_label,   min_term = round(nrow(mat) * 0.01),   stat = \"pvalue\",   min_stat = ifelse(stat == \"count\", 5, 0.05),   exclude_words = character(0),   max_words = 6,   word_cloud_grob_param = list(),   fontsize_range = c(4, 16),   bg_gp = gpar(fill = \"#DDDDDD\", col = \"#AAAAAA\") )"},{"path":"/reference/summarizeGO.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A simplified way to visualize enrichment in GO clusters — summarizeGO","text":"go_id vector GO IDs. value list numeric value associate go_id. suggest use -log10(p.adjust) -log2(fold enrichment) values. aggregate Function aggregate values GO cluster. method Method clustering matrix. See cluster_terms(). control list parameters controlling clustering method, passed cluster_terms(). verbose Whether print messages. axis_label X-axis label. title Title whole plot. legend_title Title legend. min_term Minimal number functional terms cluster. clusters size less min_term merged one separated cluster heatmap. stat Type value mapping font size keywords word clouds. two options: \"count\": simply number keywords; \"pvalue\": enrichment keywords performed (fisher's exact test) -log10(pvalue) used map font sizes. min_stat Minimal value stat selecting keywords. exclude_words Words excluded word cloud. max_words Maximal number words visualized word cloud. word_cloud_grob_param list graphic parameters passed word_cloud_grob. fontsize_range range font size. value numeric vector length two. font size interpolation linear. bg_gp Graphics parameters controlling word cloud annotation background.","code":""},{"path":"/reference/summarizeGO.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A simplified way to visualize enrichment in GO clusters — summarizeGO","text":"several ways specify GO IDs associated values. specify value named vector GO IDs names. specify value list numeric named vectors. case, value contains multiple enrichment results. Please refer https://jokergoo.github.io/2023/10/02/simplified-simplifyenrichment-plot/ examples function.","code":""},{"path":"/reference/word_cloud_grob.html","id":null,"dir":"Reference","previous_headings":"","what":"A simple grob for the word cloud — word_cloud_grob","title":"A simple grob for the word cloud — word_cloud_grob","text":"simple grob word cloud","code":""},{"path":"/reference/word_cloud_grob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A simple grob for the word cloud — word_cloud_grob","text":"","code":"word_cloud_grob(   text,   fontsize,   line_space = unit(4, \"pt\"),   word_space = unit(4, \"pt\"),   max_width = unit(80, \"mm\"),   col = function(fs) circlize::rand_color(length(fs), luminosity = \"dark\"),   add_new_line = FALSE,   test = FALSE )  # S3 method for word_cloud widthDetails(x)  # S3 method for word_cloud heightDetails(x)"},{"path":"/reference/word_cloud_grob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A simple grob for the word cloud — word_cloud_grob","text":"text vector words. fontsize corresponding font size. frequency words known, scale_fontsize can used linearly interpolate frequencies font sizes. line_space Space lines. value can grid::unit object numeric scalar measured mm. word_space Space words. value can grid::unit object numeric scalar measured mm. max_width maximal width viewport put word cloud. value can grid::unit object numeric scalar measured mm. Note might larger final width returned grob object. col Colors words. value can vector, numeric character, length text. self-defined function takes font size vector argument. function return color vector. See Examples. add_new_line Whether add new line every word? TRUE, word separated line. test Internally used. basically adds borders words viewport. x word_cloud grob returned word_cloud_grob.","code":""},{"path":"/reference/word_cloud_grob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A simple grob for the word cloud — word_cloud_grob","text":"grid::grob object. width height grob can get grid::grobWidth grid::grobHeight.","code":""},{"path":"/reference/word_cloud_grob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A simple grob for the word cloud — word_cloud_grob","text":"","code":"# very old R versions do not have strrep() function if(!exists(\"strrep\")) {     strrep = function(x, i) paste(rep(x, i), collapse = \"\") } words = sapply(1:30, function(x) strrep(sample(letters, 1), sample(3:10, 1))) require(grid) gb = word_cloud_grob(words, fontsize = runif(30, min = 5, max = 30),      max_width = 100) grid.newpage(); grid.draw(gb)   # color as a single scalar gb = word_cloud_grob(words, fontsize = runif(30, min = 5, max = 30),      max_width = 100, col = 1) grid.newpage(); grid.draw(gb)   # color as a vector gb = word_cloud_grob(words, fontsize = runif(30, min = 5, max = 30),      max_width = 100, col = 1:30) grid.newpage(); grid.draw(gb)   # color as a function require(circlize) #> Loading required package: circlize #> ======================================== #> circlize version 0.4.16 #> CRAN page: https://cran.r-project.org/package=circlize #> Github page: https://github.com/jokergoo/circlize #> Documentation: https://jokergoo.github.io/circlize_book/book/ #>  #> If you use it in published research, please cite: #> Gu, Z. circlize implements and enhances circular visualization #>   in R. Bioinformatics 2014. #>  #> This message can be suppressed by: #>   suppressPackageStartupMessages(library(circlize)) #> ======================================== col_fun = colorRamp2(c(5, 17, 30), c(\"blue\", \"black\", \"red\")) gb = word_cloud_grob(words, fontsize = runif(30, min = 5, max = 30),      max_width = 100, col = function(fs) col_fun(fs)) grid.newpage(); grid.draw(gb)"}]
